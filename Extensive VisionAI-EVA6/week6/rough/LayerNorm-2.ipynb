{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"LayerNorm-2.ipynb","provenance":[{"file_id":"1a9Qxpvbl78xoM5XOM28tISwQ8nmIg--x","timestamp":1623023397664}],"collapsed_sections":[],"authorship_tag":"ABX9TyPP92duubuCRXxx+TOUZIzq"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c9d6f1025d4f42ff80c9b3202fa7460f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_34601d9b85aa444d803971581199a2f9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ea4ed9f57798489b8ec4669acec96cd1","IPY_MODEL_42d2ee36c7624187a706d5af95193750"]}},"34601d9b85aa444d803971581199a2f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea4ed9f57798489b8ec4669acec96cd1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_888ae7f1dcf84320b7bc7d413f7eb5fe","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":9912422,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":9912422,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d41b1db75132433b9ba3d875bf92876d"}},"42d2ee36c7624187a706d5af95193750":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_193e6c8704cd4ae3b5dca6409d5b3969","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9913344/? [08:57&lt;00:00, 18429.05it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aad5a19a91974d669b111da7547fb83c"}},"888ae7f1dcf84320b7bc7d413f7eb5fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d41b1db75132433b9ba3d875bf92876d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"193e6c8704cd4ae3b5dca6409d5b3969":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aad5a19a91974d669b111da7547fb83c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb4c737b1fec46dba71933912ba3ee31":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_514f7efbc7ce4819b0f195df677c067d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7a27918d8c5e4faa876b36cf45f8a63d","IPY_MODEL_9193bfc0ab084f998066b87ef8160452"]}},"514f7efbc7ce4819b0f195df677c067d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7a27918d8c5e4faa876b36cf45f8a63d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c016b2dfefaf4b1186b8694c01371c81","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":28881,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":28881,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b9fcaf67c7454724a1adadc3736a9346"}},"9193bfc0ab084f998066b87ef8160452":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_95ce3d00c11b430bb970ca05ccac8188","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29696/? [03:52&lt;00:00, 127.49it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fa3dad292e1f42ab9d0febc6c7a9a083"}},"c016b2dfefaf4b1186b8694c01371c81":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b9fcaf67c7454724a1adadc3736a9346":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95ce3d00c11b430bb970ca05ccac8188":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fa3dad292e1f42ab9d0febc6c7a9a083":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b5072e2b9a0c4876b74f30b9cd0b7e7d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_53df4ae3cc774111abbb3592691b0e1b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7f29ee3cb08345bb905ffca8d0d510a5","IPY_MODEL_3dbc0e43045f4ee4b6dc56c498c9645d"]}},"53df4ae3cc774111abbb3592691b0e1b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7f29ee3cb08345bb905ffca8d0d510a5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0a32995bc76447fcb69cb1276b502a2a","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1648877,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1648877,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db5dc74355644d858c409d298f6be55a"}},"3dbc0e43045f4ee4b6dc56c498c9645d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c3319973660e4d76bfb9f440654a17ac","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1649664/? [00:51&lt;00:00, 32251.82it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_81d149f22dce4747b5868fe8a45b4454"}},"0a32995bc76447fcb69cb1276b502a2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"db5dc74355644d858c409d298f6be55a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c3319973660e4d76bfb9f440654a17ac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"81d149f22dce4747b5868fe8a45b4454":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4614a20dfded4aa6ab0ee53ab53c6ca1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_dab3d23c086d44b9918a00e89457e56f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6016fe40a48d4f53b0eddbb370c448d3","IPY_MODEL_0945a5fa8a6349c38d14fb9838f080b7"]}},"dab3d23c086d44b9918a00e89457e56f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6016fe40a48d4f53b0eddbb370c448d3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6b740b76494a41789bce6e80371f13a0","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":4542,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4542,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c024e72d89f640d39be28c4eabeac83b"}},"0945a5fa8a6349c38d14fb9838f080b7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9bd5b7b84349455eb61af00071c7fbbb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5120/? [03:01&lt;00:00, 28.24it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e9a44c6f968d4573a38d4f43cf40098c"}},"6b740b76494a41789bce6e80371f13a0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c024e72d89f640d39be28c4eabeac83b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9bd5b7b84349455eb61af00071c7fbbb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e9a44c6f968d4573a38d4f43cf40098c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"t2jsUEUjox8s","executionInfo":{"status":"ok","timestamp":1623112223516,"user_tz":-330,"elapsed":2668,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}}},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":728,"referenced_widgets":["c9d6f1025d4f42ff80c9b3202fa7460f","34601d9b85aa444d803971581199a2f9","ea4ed9f57798489b8ec4669acec96cd1","42d2ee36c7624187a706d5af95193750","888ae7f1dcf84320b7bc7d413f7eb5fe","d41b1db75132433b9ba3d875bf92876d","193e6c8704cd4ae3b5dca6409d5b3969","aad5a19a91974d669b111da7547fb83c","fb4c737b1fec46dba71933912ba3ee31","514f7efbc7ce4819b0f195df677c067d","7a27918d8c5e4faa876b36cf45f8a63d","9193bfc0ab084f998066b87ef8160452","c016b2dfefaf4b1186b8694c01371c81","b9fcaf67c7454724a1adadc3736a9346","95ce3d00c11b430bb970ca05ccac8188","fa3dad292e1f42ab9d0febc6c7a9a083","b5072e2b9a0c4876b74f30b9cd0b7e7d","53df4ae3cc774111abbb3592691b0e1b","7f29ee3cb08345bb905ffca8d0d510a5","3dbc0e43045f4ee4b6dc56c498c9645d","0a32995bc76447fcb69cb1276b502a2a","db5dc74355644d858c409d298f6be55a","c3319973660e4d76bfb9f440654a17ac","81d149f22dce4747b5868fe8a45b4454","4614a20dfded4aa6ab0ee53ab53c6ca1","dab3d23c086d44b9918a00e89457e56f","6016fe40a48d4f53b0eddbb370c448d3","0945a5fa8a6349c38d14fb9838f080b7","6b740b76494a41789bce6e80371f13a0","c024e72d89f640d39be28c4eabeac83b","9bd5b7b84349455eb61af00071c7fbbb","e9a44c6f968d4573a38d4f43cf40098c"]},"id":"TdiE4A1JAM31","executionInfo":{"status":"ok","timestamp":1623112580779,"user_tz":-330,"elapsed":357277,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"e2a57a54-b981-4b44-d4e4-0d22b7713381"},"source":["# Train Phase transformations\n","train_transforms = transforms.Compose([\n","                                      #transforms.ToPILImage(),\n","                                      #transforms.Resize((28, 28)),\n","                                      #transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n","                                       #transforms.RandomRotation((-7.0, 7.0), fill=(0.13,)),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize((0.1307,), (0.3081,)), # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n","                                       # Note the difference between (0.1307) and (0.1307,)\n","                                       #transforms.RandomRotation((-5.0, 5.0), fill=(-0.42,)),\n","                                       transforms.RandomAffine((-5,5), translate=None, scale=None, shear=5, resample=False, fillcolor=(-0.42,))\n","                                       ])\n","\n","# Test Phase transformations\n","test_transforms = transforms.Compose([\n","                                      #  transforms.Resize((28, 28)),\n","                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n","                                       transforms.ToTensor(),\n","                                       transforms.Normalize((0.1307,), (0.3081,))\n","                                       ])\n","\n","train = datasets.MNIST('./data', train=True, download=True, transform=train_transforms)\n","test = datasets.MNIST('./data', train=False, download=True, transform=test_transforms)\n","\n","SEED = 1\n","\n","# CUDA?\n","cuda = torch.cuda.is_available()\n","print(\"CUDA Available?\", cuda)\n","\n","# For reproducibility\n","torch.manual_seed(SEED)\n","\n","if cuda:\n","    torch.cuda.manual_seed(SEED)\n","\n","# dataloader arguments - something you'll fetch these from cmdprmt\n","dataloader_args = dict(shuffle=True, batch_size=64, num_workers=4, pin_memory=True) if cuda else dict(shuffle=True, batch_size=64)\n","\n","# train dataloader\n","train_loader = torch.utils.data.DataLoader(train, **dataloader_args)\n","\n","# test dataloader\n","test_loader = torch.utils.data.DataLoader(test, **dataloader_args)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:1315: UserWarning: Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\n","  \"Argument resample is deprecated and will be removed since v0.10.0. Please, use interpolation instead\"\n","/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:1329: UserWarning: Argument fillcolor is deprecated and will be removed since v0.10.0. Please, use fill instead\n","  \"Argument fillcolor is deprecated and will be removed since v0.10.0. Please, use fill instead\"\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c9d6f1025d4f42ff80c9b3202fa7460f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=9912422.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb4c737b1fec46dba71933912ba3ee31","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=28881.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5072e2b9a0c4876b74f30b9cd0b7e7d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=1648877.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4614a20dfded4aa6ab0ee53ab53c6ca1","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=4542.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n","\n","Processing...\n","Done!\n","CUDA Available? True\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:143.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"QBj0TbcEDSCo","executionInfo":{"status":"ok","timestamp":1623112597379,"user_tz":-330,"elapsed":420,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}}},"source":["# from tqdm.notebook import tqdm\n","\n","#Use scheduler\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    # pbar = tqdm(train_loader)\n","    train_loss = 0\n","    correct = 0\n","    num_loops = 0\n","    criterion = nn.CrossEntropyLoss()\n","    # for batch_idx, (data, target) in enumerate(pbar):\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        # loss = F.nll_loss(output, target)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        # pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n","        train_loss += loss.item()\n","        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","        num_loops +=1\n"," \n","    train_loss /= num_loops\n","    # scheduler.step()\n","    # scheduler.step(train_loss)\n","    hist_train_loss.append(train_loss)\n","    hist_train_acc.append(100. * correct / len(train_loader.dataset))\n","    print(\"Training Average loss: {:.6f}, Accuracy = ({:.6f}%)\".format(train_loss, 100. * correct / len(train_loader.dataset)))\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","    hist_test_loss.append(test_loss)\n","    hist_test_acc.append(100. * correct / len(test_loader.dataset))\n","\n","    print('Test set: Average loss: {:.6f}, Accuracy: {}/{} ({:.6f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))\n","    \n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","plt.rcParams['figure.figsize'] = [15, 6]\n","\n","def training_curves():\n","  plt.subplot(1,2, 1)\n","\n","  plt.plot(np.array(hist_test_acc))\n","  plt.plot(np.array(hist_train_acc), 'r')\n","  plt.legend([\"test_acc\", \"train_acc\"])\n","  plt.title(\"Accuracy per epoch\")\n","\n","  plt.subplot(1,2,2)\n","  plt.plot(hist_test_loss)\n","  plt.plot(hist_train_loss, 'r')\n","  plt.legend([\"test_loss\", \"train_loss\"])\n","  plt.title(\"Loss per epoch\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"fIDt65VLw_zA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623112600117,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"e2b0fc3f-c923-4148-e2cd-13cd0426bb2c"},"source":["def Gen_BN(out_features, channel_size, norm_type):\n","  if norm_type==\"BN\":\n","    m = nn.BatchNorm2d(out_features)\n","  elif norm_type == \"LN\":\n","    # x = torch.rand(2,out_features,channel_size,channel_size)\n","    # m = nn.LayerNorm(x.size()[1:])\n","    m = nn.LayerNorm((out_features, channel_size, channel_size))\n","  return m\n","\n","def conv_output_shape(h_w, kernel_size=1, stride=1, pad=0, dilation=1):\n","    \"\"\"\n","    Utility function for computing output of convolutions\n","    takes a tuple of (h,w) and returns a tuple of (h,w)\n","    \"\"\"\n","    \n","    if type(h_w) is not tuple:\n","        h_w = (h_w, h_w)\n","    \n","    if type(kernel_size) is not tuple:\n","        kernel_size = (kernel_size, kernel_size)\n","    \n","    if type(stride) is not tuple:\n","        stride = (stride, stride)\n","    \n","    if type(pad) is not tuple:\n","        pad = (pad, pad)\n","    \n","    h = (h_w[0] + (2 * pad[0]) - (dilation * (kernel_size[0] - 1)) - 1)// stride[0] + 1\n","    w = (h_w[1] + (2 * pad[1]) - (dilation * (kernel_size[1] - 1)) - 1)// stride[1] + 1\n","    \n","    return h, w\n","\n","x, y = conv_output_shape(28, 3, 1,0,1)\n","x, y\n","temp = Gen_BN(12, 28, \"LN\")\n","temp"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LayerNorm((12, 28, 28), eps=1e-05, elementwise_affine=True)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkno8_gkChRF","executionInfo":{"status":"ok","timestamp":1623115154302,"user_tz":-330,"elapsed":433,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"e1b74b47-f13e-47b0-a585-82ea4d81711f"},"source":["dropout_value = 0.05\n","\n","\n","class Net2(nn.Module):\n","    def get_bn(self, out_features, channel_size, norm_type):\n","        if norm_type==\"BN\":\n","          m = nn.BatchNorm2d(out_features)\n","        elif norm_type == \"LN\":\n","          m = nn.LayerNorm((out_features, channel_size, channel_size))\n","        return m\n","\n","    def conv_block(self, in_features, out_features, kernel_size, input_channel_size, Norm_type,pading=0, last_block=True):\n","      # convolution\n","      layers = []\n","      layers = [nn.Conv2d(in_features, out_features, kernel_size, padding=pading, bias=False), nn.ReLU()]\n","      out_img_size, _ = conv_output_shape(input_channel_size, kernel_size, stride=1,pad=pading,dilation=1) # get the image size after convolution\n","\n","      #Generate Normalization\n","      norm_list = ['BN', 'LN'] # this is the list of normalization that is allowed. \n","      if (Norm_type in norm_list) and (kernel_size != 1) and (last_block):   # Check if normalization is in the list, or if its not 1x1 or if its not last block. \n","        BN = self.get_bn(out_features, out_img_size, Norm_type)\n","        layers.append(BN)\n","\n","      # Add Dropout - Check if its not last block or 1x1 convolution.   \n","      if kernel_size !=1 and last_block :\n","        layers.append(nn.Dropout(dropout_value))\n","      block = nn.Sequential(*layers)\n","      return block, out_img_size\n","\n","    def max_pool_block(self, kernal_size, stride, img_size):\n","        pool = nn.MaxPool2d(kernal_size, stride) # output_size = 13\n","        out_img_size,_ = conv_output_shape(img_size,kernal_size, stride)\n","        return pool, out_img_size\n","\n","    def __init__(self, Norm_type, input_img_size=(1,28,28)):\n","        super(Net2, self).__init__()\n","        self.convblock1, img_size = self.conv_block(1,8,3,input_img_size[1],Norm_type) # input kernal, output_kernals, convolution, input image size, padding, normalization type #26\n","        self.convblock2, img_size = self.conv_block(8,16,3,img_size,Norm_type) #24\n","        self.pool1, img_size = self.max_pool_block(2,2, img_size)  #12\n","        self.convblock4, img_size = self.conv_block(16,8,1,img_size,Norm_type) #12\n","        self.convblock5, img_size = self.conv_block(8,16,3,img_size,Norm_type) #10\n","        self.convblock6, img_size = self.conv_block(16,20,3,img_size,Norm_type) #8\n","        self.convblock7, img_size = self.conv_block(20,8,1,img_size,Norm_type) #8\n","        self.convblock8, img_size = self.conv_block(8,16,3,img_size,Norm_type, last_block=False) #6\n","\n","        self.gap = nn.Sequential(nn.AvgPool2d(kernel_size=6)) # output_size = 1\n","        self.fc1 = nn.Linear(16, 10)\n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.convblock2(x)\n","        #x = self.convblock3(x)\n","        x = self.pool1(x)\n","        x = self.convblock4(x)\n","        x = self.convblock5(x)\n","        x = self.convblock6(x)\n","        x = self.convblock7(x)\n","        x = self.convblock8(x)\n","        x = self.gap(x)\n","        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n","        x = self.fc1(x)\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x, dim=-1)\n","\n","model = Net2(\"BN\", input_img_size=(1, 28, 28)).to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 26, 26]              72\n","              ReLU-2            [-1, 8, 26, 26]               0\n","       BatchNorm2d-3            [-1, 8, 26, 26]              16\n","           Dropout-4            [-1, 8, 26, 26]               0\n","            Conv2d-5           [-1, 16, 24, 24]           1,152\n","              ReLU-6           [-1, 16, 24, 24]               0\n","       BatchNorm2d-7           [-1, 16, 24, 24]              32\n","           Dropout-8           [-1, 16, 24, 24]               0\n","         MaxPool2d-9           [-1, 16, 12, 12]               0\n","           Conv2d-10            [-1, 8, 12, 12]             128\n","             ReLU-11            [-1, 8, 12, 12]               0\n","           Conv2d-12           [-1, 16, 10, 10]           1,152\n","             ReLU-13           [-1, 16, 10, 10]               0\n","      BatchNorm2d-14           [-1, 16, 10, 10]              32\n","          Dropout-15           [-1, 16, 10, 10]               0\n","           Conv2d-16             [-1, 20, 8, 8]           2,880\n","             ReLU-17             [-1, 20, 8, 8]               0\n","      BatchNorm2d-18             [-1, 20, 8, 8]              40\n","          Dropout-19             [-1, 20, 8, 8]               0\n","           Conv2d-20              [-1, 8, 8, 8]             160\n","             ReLU-21              [-1, 8, 8, 8]               0\n","           Conv2d-22             [-1, 16, 6, 6]           1,152\n","             ReLU-23             [-1, 16, 6, 6]               0\n","        AvgPool2d-24             [-1, 16, 1, 1]               0\n","           Linear-25                   [-1, 10]             170\n","================================================================\n","Total params: 6,986\n","Trainable params: 6,986\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.59\n","Params size (MB): 0.03\n","Estimated Total Size (MB): 0.62\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FXk3KXBdvIKw","executionInfo":{"status":"ok","timestamp":1623030581632,"user_tz":-330,"elapsed":338,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"df66e21b-2203-48e3-aa54-aeb0f285d0b9"},"source":["# class Net1(nn.Module):\n","\n","\n","#     def get_bn(self, out_features, channel_size, norm_type):\n","#         if norm_type==\"BN\":\n","#           m = nn.BatchNorm2d(out_features)\n","#         elif norm_type == \"LN\":\n","#           m = nn.LayerNorm((out_features, channel_size, channel_size))\n","#         return m\n","\n","#     def conv_block(self, in_features, out_features, kernel_size, input_channel_size, pad, Norm_type):\n","#       # convolution\n","#       layers = []\n","#       layers = [nn.Conv2d(in_features, out_features, kernel_size, padding=pad, bias=False), nn.ReLU()]\n","#       out_img_size, _ = conv_output_shape(input_channel_size, kernel_size, stride=1,pad=pad,dilation=1) # get the image size after convolution\n","\n","#       #Generate Normalization\n","#       norm_list = ['BN', 'LN'] # this is the list of normalization that is allowed. \n","#       if Norm_type in norm_list:\n","#         BN = self.get_bn(out_features, out_img_size, Norm_type)\n","#         layers.append(BN)\n","#       block = nn.Sequential(*layers)\n","#       return block, out_img_size\n","\n","#     def max_pool_block(self, kernal_size, stride, img_size):\n","#         pool = nn.MaxPool2d(kernal_size, stride) # output_size = 13\n","#         out_img_size,_ = conv_output_shape(img_size,kernal_size, stride)\n","#         return pool, out_img_size\n","\n","#     def __init__(self, Norm_type, input_img_size=(1,28,28)):\n","#         super(Net1, self).__init__()\n","#         self.convblock1, img_size = self.conv_block(1,8,3,input_img_size[1],1,Norm_type) # input kernal, output_kernals, convolution, input image size, \n","#         self.convblock1a, img_size = self.conv_block(8,8,3,img_size,0,Norm_type) # input kernal, output_kernals, convolution, input image size, \n","#         self.pool1, img_size = self.max_pool_block(2,2, img_size) \n","#         self.convblock2, img_size = self.conv_block(8, 16, 3,img_size,0, Norm_type)\n","#         self.pool2, img_size = self.max_pool_block(2,2, img_size)\n","#         self.convblock3,img_size = self.conv_block(16, 16, 3, img_size,0, Norm_type)\n","#         self.gap = nn.Sequential(nn.AvgPool2d(kernel_size=3)) # output_size = 1\n","#         self.fc1 = nn.Linear(16, 10)\n","\n","#     def forward(self, x):\n","#         x = self.convblock1(x)\n","#         x = self.convblock1a(x)\n","#         x = self.pool1(x)\n","#         x = self.convblock2(x)\n","#         x = self.pool2(x)\n","#         x = self.convblock3(x)\n","#         x = self.gap(x)\n","#         x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n","#         x = self.fc1(x)\n","#         x = x.view(-1, 10)\n","#         return F.log_softmax(x, dim=-1)\n","\n","# model = Net1(\"LN\", input_img_size=(1, 28, 28)).to(device)\n","# summary(model, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 28, 28]              72\n","              ReLU-2            [-1, 8, 28, 28]               0\n","         LayerNorm-3            [-1, 8, 28, 28]          12,544\n","            Conv2d-4            [-1, 8, 26, 26]             576\n","              ReLU-5            [-1, 8, 26, 26]               0\n","         LayerNorm-6            [-1, 8, 26, 26]          10,816\n","         MaxPool2d-7            [-1, 8, 13, 13]               0\n","            Conv2d-8           [-1, 16, 11, 11]           1,152\n","              ReLU-9           [-1, 16, 11, 11]               0\n","        LayerNorm-10           [-1, 16, 11, 11]           3,872\n","        MaxPool2d-11             [-1, 16, 5, 5]               0\n","           Conv2d-12             [-1, 16, 3, 3]           2,304\n","             ReLU-13             [-1, 16, 3, 3]               0\n","        LayerNorm-14             [-1, 16, 3, 3]             288\n","        AvgPool2d-15             [-1, 16, 1, 1]               0\n","           Linear-16                   [-1, 10]             170\n","================================================================\n","Total params: 31,794\n","Trainable params: 31,794\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.33\n","Params size (MB): 0.12\n","Estimated Total Size (MB): 0.45\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kW03x5dfvPXL","executionInfo":{"status":"ok","timestamp":1623114436431,"user_tz":-330,"elapsed":83844,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"655a70c9-c626-40dd-f9ad-0536fce9d910"},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.optim.lr_scheduler import ExponentialLR\n","\n","hist_test_loss = []\n","hist_test_acc = []\n","hist_train_loss = []\n","hist_train_acc = []\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9,)\n","\n","scheduler =ReduceLROnPlateau(optimizer=optimizer, patience=2, verbose=True)\n","\n","for epoch in range(1, 4):\n","    print(\"Epoch: \", epoch)\n","    train(model, device, train_loader, optimizer, epoch)\n","    print(\"learning rate\", optimizer.param_groups[0]['lr'])\n","    test(model, device, test_loader)\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Epoch:  1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Training Average loss: 0.061735, Accuracy = (98.105000%)\n","learning rate 0.1\n","Test set: Average loss: 0.059488, Accuracy: 9816/10000 (98.160000%)\n","\n","Epoch:  2\n","Training Average loss: 0.056768, Accuracy = (98.268333%)\n","learning rate 0.1\n","Test set: Average loss: 0.031461, Accuracy: 9900/10000 (99.000000%)\n","\n","Epoch:  3\n","Training Average loss: 0.049957, Accuracy = (98.491667%)\n","learning rate 0.1\n","Test set: Average loss: 0.044592, Accuracy: 9852/10000 (98.520000%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o-1MLw1YvZdh"},"source":["input_size=(1, 28, 28)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"125c2sZyvZaQ","executionInfo":{"status":"ok","timestamp":1623026949053,"user_tz":-330,"elapsed":330,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"d595236e-d2ff-46d6-c8fb-a8e54485a56a"},"source":["input_size[1]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["28"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"markdown","metadata":{"id":"jdbukxwJDKIo"},"source":["## SAving the working model"]},{"cell_type":"code","metadata":{"id":"cEr5McPQvZXL"},"source":["class Net1(nn.Module):\n"," \n","\n","    def conv_block(self, in_features, out_features, kernel_size, input_channel_size, Norm_type):\n","      norm_list = ['BN', 'LN'] # this is the list of normalization that is allowed. \n","      layers = []\n","      layers = [nn.Conv2d(in_features, out_features, kernel_size, padding=0, bias=False), nn.ReLU()]\n","      # Get the output channel size\n","      x, y = conv_output_shape(input_channel_size, kernel_size, stride=1,pad=0,dilation=1)\n","      # pass the image as parameter and get the size of the image\n","      if Norm_type in norm_list:\n","        BN = Gen_BN(out_features, x, Norm_type)\n","        layers.append(BN)\n","      # layers.append(nn.BatchNorm2d(out_features))\n","      \n","      block = nn.Sequential(*layers)\n","      return block, x\n","\n","    def max_pool_block(self, kernal_size, stride, img_size):\n","        pool = nn.MaxPool2d(kernal_size, stride) # output_size = 13\n","        print(img_size)\n","        img_size,y = conv_output_shape(img_size,kernal_size, stride)\n","        print(img_size)\n","        return pool, img_size\n","\n","\n","    def __init__(self, Norm_type, input_img_size=(1,28,28)):\n","        super(Net1, self).__init__()\n","        \n","        self.convblock1, img_size = self.conv_block(1,8,3,input_img_size[1],Norm_type) # input kernal, output_kernals, convolution, input image size, \n","        self.pool1, img_size = self.max_pool_block(2,2, img_size) \n","\n","\n","        # self.pool1 = nn.MaxPool2d(2, 2) # output_size = 13\n","        # img_size,y = conv_output_shape(img_size,2,2)\n","        self.convblock2, img_size = self.conv_block(8, 16, 3,img_size, Norm_type)\n","        self.pool2, img_size = self.max_pool_block(2,2, img_size)\n","        # self.pool2 = nn.MaxPool2d(2, 2) # output_size = 6\n","        # img_size,y = conv_output_shape(img_size,2,2)\n","        self.convblock3,img_size = self.conv_block(16, 16, 3, img_size, Norm_type)\n","\n","\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=3)\n","        ) # output_size = 1\n","\n","        self.fc1 = nn.Linear(16, 10)\n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.pool1(x)\n","        x = self.convblock2(x)\n","        x = self.pool2(x)\n","        x = self.convblock3(x)\n","\n","        x = self.gap(x)\n","        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n","        x = self.fc1(x)\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x, dim=-1)\n","\n","model = Net1(\"BN\", input_img_size=(1, 28, 28)).to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kG-BzCZxvZUX"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DQhl6nAyvZRL"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5IZBWGSivPTk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C10QT35zvPQH"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zpfxjFa_vPLj"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SD8_EXo365Yb","executionInfo":{"status":"ok","timestamp":1622991256404,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"cb51fb70-49a1-4d54-ef76-d7ef731fce27"},"source":["class Net1(nn.Module):\n","\n","    def __init__(self):\n","      \n","        super(Net1, self).__init__()\n","\n","        # Input Block\n","        self.convblock1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3, 3), padding=0, bias=False), #\n","            nn.ReLU(),\n","            # LNorm()\n","            # nn.LayerNorm((8,26,26)),\n","            nn.BatchNorm2d(8),\n","        ) # output_size = 26\n","\n","        # TRANSITION BLOCK 1\n","        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 13\n","\n","        # CONVOLUTION BLOCK 2\n","        self.convblock2 = nn.Sequential(\n","            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            # nn.LayerNorm((16,11,11)),\n","            nn.BatchNorm2d(16),\n","        ) # output_size = 11\n","\n","        # TRANSITION BLOCK 2\n","        self.pool2 = nn.MaxPool2d(2, 2) # output_size = 6\n","\n","        self.convblock3 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(16),\n","            # nn.LayerNorm((16,3,3)),\n","        ) # output_size = 4\n","\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=3)\n","        ) # output_size = 1\n","\n","        self.fc1 = nn.Linear(16, 10)\n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.pool1(x)\n","        x = self.convblock2(x)\n","        x = self.pool2(x)\n","        x = self.convblock3(x)\n","\n","        x = self.gap(x)\n","        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n","        x = self.fc1(x)\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x, dim=-1)\n","\n","model = Net1().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 26, 26]              72\n","              ReLU-2            [-1, 8, 26, 26]               0\n","       BatchNorm2d-3            [-1, 8, 26, 26]              16\n","         MaxPool2d-4            [-1, 8, 13, 13]               0\n","            Conv2d-5           [-1, 16, 11, 11]           1,152\n","              ReLU-6           [-1, 16, 11, 11]               0\n","       BatchNorm2d-7           [-1, 16, 11, 11]              32\n","         MaxPool2d-8             [-1, 16, 5, 5]               0\n","            Conv2d-9             [-1, 16, 3, 3]           2,304\n","             ReLU-10             [-1, 16, 3, 3]               0\n","      BatchNorm2d-11             [-1, 16, 3, 3]              32\n","        AvgPool2d-12             [-1, 16, 1, 1]               0\n","           Linear-13                   [-1, 10]             170\n","================================================================\n","Total params: 3,778\n","Trainable params: 3,778\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.18\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.20\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PiNmbmkFYMWR"},"source":["class Print(nn.Module):\n","    def forward(self, x):\n","        print(x.size())\n","        return x\n","\n","def get_output_shape(model, image_dim):\n","    return model(torch.rand(*(image_dim))).data.shape\n","\n","# def conv_output_shape(h_w, kernel_size=1, stride=1, pad=0, dilation=1):\n","#     from math import floor\n","#     if type(kernel_size) is not tuple:\n","#         kernel_size = (kernel_size, kernel_size)\n","#     h = floor( ((h_w[0] + (2 * pad) - ( dilation * (kernel_size[0] - 1) ) - 1 )/ stride) + 1)\n","#     w = floor( ((h_w[1] + (2 * pad) - ( dilation * (kernel_size[1] - 1) ) - 1 )/ stride) + 1)\n","#     return h, w\n","\n","def conv_output_shape(h_w, kernel_size=1, stride=1, pad=0, dilation=1):\n","    \"\"\"\n","    Utility function for computing output of convolutions\n","    takes a tuple of (h,w) and returns a tuple of (h,w)\n","    \"\"\"\n","    \n","    if type(h_w) is not tuple:\n","        h_w = (h_w, h_w)\n","    \n","    if type(kernel_size) is not tuple:\n","        kernel_size = (kernel_size, kernel_size)\n","    \n","    if type(stride) is not tuple:\n","        stride = (stride, stride)\n","    \n","    if type(pad) is not tuple:\n","        pad = (pad, pad)\n","    \n","    h = (h_w[0] + (2 * pad[0]) - (dilation * (kernel_size[0] - 1)) - 1)// stride[0] + 1\n","    w = (h_w[1] + (2 * pad[1]) - (dilation * (kernel_size[1] - 1)) - 1)// stride[1] + 1\n","    \n","    return h, w"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-W9XIlGaiuI","executionInfo":{"status":"ok","timestamp":1622991260733,"user_tz":-330,"elapsed":482,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"a33fb0e9-7f32-428d-f7f9-d4545ca7185e"},"source":["x, y = conv_output_shape(28, 3, 1,0,1)\n","x, y\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(26, 26)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_8yaw_QCvltn","executionInfo":{"status":"ok","timestamp":1622991264446,"user_tz":-330,"elapsed":643,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"fd380d2a-0106-4b52-ea8b-91095001384b"},"source":["cfg = [8, \"M\", 16, 'M', 16]\n","\n","\n","cnt=0\n","for x in cfg:\n","  cnt+= 1\n","  print(cnt)\n","  len(cfg)\n","  if cnt == len(cfg):\n","    print('reached the end')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1\n","2\n","3\n","4\n","5\n","reached the end\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OLq-3DODNfIa"},"source":["cfg = {\n","    'basic': [8, \"M\", 16, 'M', 16]\n","}\n","\n","\n","class Building_Net(nn.Module):\n","  def __init__(self, m_name, img):\n","    super(Building_Net, self).__init__()\n","    self.shape = img.shape[1:]\n","    print(self.shape)\n","    self.features = self._make_layers(cfg[m_name], self.shape)\n","\n","    self.fc1 = nn.Linear(16, 10)\n","\n","\n","  def _make_layers(self, cfg, initial_shape):\n","    layers = []\n","    in_channels = 1\n","    updated_shape = initial_shape[1]\n","    # print('updated shape', updated_shape)\n","    cnt=0\n","    \n","    for x in cfg:\n","      cnt += 1\n","      if x == 'M':\n","          layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","          updated_shape = conv_output_shape(updated_shape, 2, 2)\n","          # print('max pool', updated_shape)\n","\n","      else:\n","          layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=0, bias=False)]\n","          layers += [nn.ReLU()]\n","          # if cnt != len(cfg):\n","          layers += [nn.BatchNorm2d(x)]\n","          updated_shape = conv_output_shape(updated_shape, 3, 1)\n","          # print('conv ', updated_shape)\n","                      \n","          in_channels = x\n","\n","          # print(layers)\n","      \n","    layers += [nn.AvgPool2d(kernel_size=3)]\n","    return nn.Sequential(*layers)\n","\n","\n","  def forward(self,x):\n","    x = self.features(x)\n","    # x = self.gap(x)\n","    x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n","    x = self.fc1(x)\n","    x = x.view(-1, 10)\n","    return F.log_softmax(x, dim=-1)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ec27S-imV6C8","executionInfo":{"status":"ok","timestamp":1622993504372,"user_tz":-330,"elapsed":488,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"b757b607-79b5-45da-c04b-6bb33a7ed31e"},"source":["model2 = Building_Net('basic',torch.rand(2,1,28,28)).to(device)\n","summary(model2, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([1, 28, 28])\n","[Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), bias=False), ReLU(), BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]\n","[Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), bias=False), ReLU(), BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), bias=False), ReLU(), BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]\n","[Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), bias=False), ReLU(), BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), bias=False), ReLU(), BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False), ReLU(), BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)]\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 26, 26]              72\n","              ReLU-2            [-1, 8, 26, 26]               0\n","       BatchNorm2d-3            [-1, 8, 26, 26]              16\n","         MaxPool2d-4            [-1, 8, 13, 13]               0\n","            Conv2d-5           [-1, 16, 11, 11]           1,152\n","              ReLU-6           [-1, 16, 11, 11]               0\n","       BatchNorm2d-7           [-1, 16, 11, 11]              32\n","         MaxPool2d-8             [-1, 16, 5, 5]               0\n","            Conv2d-9             [-1, 16, 3, 3]           2,304\n","             ReLU-10             [-1, 16, 3, 3]               0\n","      BatchNorm2d-11             [-1, 16, 3, 3]              32\n","        AvgPool2d-12             [-1, 16, 1, 1]               0\n","           Linear-13                   [-1, 10]             170\n","================================================================\n","Total params: 3,778\n","Trainable params: 3,778\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.18\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.20\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q10yJysHNe77","executionInfo":{"status":"ok","timestamp":1622993028663,"user_tz":-330,"elapsed":474,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"d9574cec-754f-4012-ad9e-f65e1ec8b1aa"},"source":["model2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Building_Net(\n","  (features): Sequential(\n","    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (1): ReLU()\n","    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (5): ReLU()\n","    (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (8): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (9): ReLU()\n","    (10): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): AvgPool2d(kernel_size=3, stride=3, padding=0)\n","  )\n","  (fc1): Linear(in_features=16, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_rlcrEiNe3o","executionInfo":{"status":"ok","timestamp":1622993029369,"user_tz":-330,"elapsed":9,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"e30cf3a5-f7c2-4f0a-fca8-d62afb3da38f"},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net1(\n","  (convblock1): Sequential(\n","    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (1): ReLU()\n","  )\n","  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (convblock2): Sequential(\n","    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (1): ReLU()\n","  )\n","  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (convblock3): Sequential(\n","    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (1): ReLU()\n","  )\n","  (gap): Sequential(\n","    (0): AvgPool2d(kernel_size=3, stride=3, padding=0)\n","  )\n","  (fc1): Linear(in_features=16, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":68}]},{"cell_type":"code","metadata":{"id":"YYIqHSp_65IS"},"source":["hist_test_loss = []\n","hist_test_acc = []\n","hist_train_loss = []\n","hist_train_acc = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eMofTPe7oxvL","colab":{"base_uri":"https://localhost:8080/","height":560},"executionInfo":{"status":"error","timestamp":1622993076710,"user_tz":-330,"elapsed":37777,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"a6b8763c-de04-464d-9bf3-b67e622a0151"},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.optim.lr_scheduler import ExponentialLR\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9,)\n","\n","scheduler =ReduceLROnPlateau(optimizer=optimizer, patience=2, verbose=True)\n","\n","for epoch in range(1, 3):\n","    print(\"Epoch: \", epoch)\n","    train(model2, device, train_loader, optimizer, epoch)\n","    print(\"learning rate\", optimizer.param_groups[0]['lr'])\n","    test(model2, device, test_loader)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch:  1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Training Average loss: 2.361981, Accuracy = (9.371667%)\n","learning rate 0.1\n","Test set: Average loss: 2.359781, Accuracy: 1015/10000 (10.150000%)\n","\n","Epoch:  2\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-fed7b2ecf3e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"learning rate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-bbca21246c22>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# for batch_idx, (data, target) in enumerate(pbar):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"SNt5IT0x741y"},"source":["class Gen_BN(nn.Module):\n","    def forward(self, x):\n","        print(x.size())\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ns55GKX_yeSU","executionInfo":{"status":"ok","timestamp":1622994753904,"user_tz":-330,"elapsed":476,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"1695e0ae-6e0c-412b-d757-03db8a4d107c"},"source":["class Net1(nn.Module):\n","\n","    def conv_block(self, in_features, out_features, kernel_size, BN_flag):\n","      layers = []\n","      layers = [nn.Conv2d(in_features, out_features, kernel_size, padding=0, bias=False),\n","                nn.ReLU()]\n","\n","      # pass the image as parameter and get the size of the image\n","      if BN_flag:\n","        layers.append(nn.BatchNorm2d(out_features))\n","      \n","      block = nn.Sequential(*layers)\n","\n","      return block\n","\n","\n","    def __init__(self):\n","        super(Net1, self).__init__()\n","\n","        self.convblock1 = self.conv_block(1,8,3,True)\n","        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 13\n","        self.convblock2 = self.conv_block(8, 16, 3, True)\n","        self.pool2 = nn.MaxPool2d(2, 2) # output_size = 6\n","        self.convblock3 = self.conv_block(16, 16, 3, True)\n","\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=3)\n","        ) # output_size = 1\n","\n","        self.fc1 = nn.Linear(16, 10)\n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.pool1(x)\n","        x = self.convblock2(x)\n","        x = self.pool2(x)\n","        x = self.convblock3(x)\n","\n","        x = self.gap(x)\n","        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n","        x = self.fc1(x)\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x, dim=-1)\n","\n","model = Net1().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 26, 26]              72\n","              ReLU-2            [-1, 8, 26, 26]               0\n","       BatchNorm2d-3            [-1, 8, 26, 26]              16\n","         MaxPool2d-4            [-1, 8, 13, 13]               0\n","            Conv2d-5           [-1, 16, 11, 11]           1,152\n","              ReLU-6           [-1, 16, 11, 11]               0\n","       BatchNorm2d-7           [-1, 16, 11, 11]              32\n","         MaxPool2d-8             [-1, 16, 5, 5]               0\n","            Conv2d-9             [-1, 16, 3, 3]           2,304\n","             ReLU-10             [-1, 16, 3, 3]               0\n","      BatchNorm2d-11             [-1, 16, 3, 3]              32\n","        AvgPool2d-12             [-1, 16, 1, 1]               0\n","           Linear-13                   [-1, 10]             170\n","================================================================\n","Total params: 3,778\n","Trainable params: 3,778\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.18\n","Params size (MB): 0.01\n","Estimated Total Size (MB): 0.20\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zvopryIT8miJ","executionInfo":{"status":"ok","timestamp":1622994768445,"user_tz":-330,"elapsed":480,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"f2f01199-545c-46b4-9bc8-eca7a8a0ef86"},"source":["model"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Net1(\n","  (convblock1): Sequential(\n","    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (1): ReLU()\n","    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (convblock2): Sequential(\n","    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (1): ReLU()\n","    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (convblock3): Sequential(\n","    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n","    (1): ReLU()\n","    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n","  (gap): Sequential(\n","    (0): AvgPool2d(kernel_size=3, stride=3, padding=0)\n","  )\n","  (fc1): Linear(in_features=16, out_features=10, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_iTL93OyePN","executionInfo":{"status":"ok","timestamp":1622994834550,"user_tz":-330,"elapsed":50878,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"dbe238b0-289d-4f63-f604-da8b9d026d70"},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.optim.lr_scheduler import ExponentialLR\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9,)\n","\n","scheduler =ReduceLROnPlateau(optimizer=optimizer, patience=2, verbose=True)\n","\n","for epoch in range(1, 3):\n","    print(\"Epoch: \", epoch)\n","    train(model, device, train_loader, optimizer, epoch)\n","    print(\"learning rate\", optimizer.param_groups[0]['lr'])\n","    test(model, device, test_loader)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch:  1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Training Average loss: 0.160809, Accuracy = (95.123333%)\n","learning rate 0.1\n","Test set: Average loss: 0.062201, Accuracy: 9790/10000 (97.900000%)\n","\n","Epoch:  2\n","Training Average loss: 0.070589, Accuracy = (97.746667%)\n","learning rate 0.1\n","Test set: Average loss: 0.063156, Accuracy: 9804/10000 (98.040000%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BfWSW9UsyeK0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5NdQIGLZzVmQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KNPCHIp5zVgz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M1W7qdHszVcB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mGcp24skyeHE"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qRVceZhapsAW"},"source":["\n","'''VGG11/13/16/19 in Pytorch.'''\n","import torch\n","import torch.nn as nn\n","\n","\n","cfg = {\n","    'VGG11': [8 ,'M',16,  16, 'M', 16,16, 16, 'M', 16, 16, 16],\n","    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n","    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n","}\n","\n","\n","class VGG(nn.Module):\n","    def __init__(self, vgg_name):\n","        super(VGG, self).__init__()\n","        self.features = self._make_layers(cfg[vgg_name])\n","        self.classifier = nn.Linear(16, 10)\n","\n","    def forward(self, x):\n","        out = self.features(x)\n","        out = out.view(out.size(0), -1)\n","        out = self.classifier(out)\n","        return out\n","\n","    def _make_layers(self, cfg):\n","        layers = []\n","        in_channels = 1\n","        for x in cfg:\n","            if x == 'M':\n","                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","            else:\n","                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n","                           nn.BatchNorm2d(x),\n","                           nn.ReLU(inplace=True)]\n","                in_channels = x\n","        layers += [nn.AvgPool2d(kernel_size=3, stride=1)]\n","        return nn.Sequential(*layers)\n","\n","\n","def test():\n","    net = VGG('VGG11')\n","    x = torch.randn(2,3,32,32)\n","    y = net(x)\n","    print(y.size())\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-8HGjaepr9H","executionInfo":{"status":"ok","timestamp":1622988846250,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"c3a2d5a8-36cd-4a86-e116-694a8ca77d64"},"source":["model2 = VGG('VGG11').to(device)\n","summary(model2, input_size=(1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1            [-1, 8, 28, 28]              80\n","       BatchNorm2d-2            [-1, 8, 28, 28]              16\n","              ReLU-3            [-1, 8, 28, 28]               0\n","         MaxPool2d-4            [-1, 8, 14, 14]               0\n","            Conv2d-5           [-1, 16, 14, 14]           1,168\n","       BatchNorm2d-6           [-1, 16, 14, 14]              32\n","              ReLU-7           [-1, 16, 14, 14]               0\n","            Conv2d-8           [-1, 16, 14, 14]           2,320\n","       BatchNorm2d-9           [-1, 16, 14, 14]              32\n","             ReLU-10           [-1, 16, 14, 14]               0\n","        MaxPool2d-11             [-1, 16, 7, 7]               0\n","           Conv2d-12             [-1, 16, 7, 7]           2,320\n","      BatchNorm2d-13             [-1, 16, 7, 7]              32\n","             ReLU-14             [-1, 16, 7, 7]               0\n","           Conv2d-15             [-1, 16, 7, 7]           2,320\n","      BatchNorm2d-16             [-1, 16, 7, 7]              32\n","             ReLU-17             [-1, 16, 7, 7]               0\n","           Conv2d-18             [-1, 16, 7, 7]           2,320\n","      BatchNorm2d-19             [-1, 16, 7, 7]              32\n","             ReLU-20             [-1, 16, 7, 7]               0\n","        MaxPool2d-21             [-1, 16, 3, 3]               0\n","           Conv2d-22             [-1, 16, 3, 3]           2,320\n","      BatchNorm2d-23             [-1, 16, 3, 3]              32\n","             ReLU-24             [-1, 16, 3, 3]               0\n","           Conv2d-25             [-1, 16, 3, 3]           2,320\n","      BatchNorm2d-26             [-1, 16, 3, 3]              32\n","             ReLU-27             [-1, 16, 3, 3]               0\n","           Conv2d-28             [-1, 16, 3, 3]           2,320\n","      BatchNorm2d-29             [-1, 16, 3, 3]              32\n","             ReLU-30             [-1, 16, 3, 3]               0\n","        AvgPool2d-31             [-1, 16, 1, 1]               0\n","           Linear-32                   [-1, 10]             170\n","================================================================\n","Total params: 17,930\n","Trainable params: 17,930\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.37\n","Params size (MB): 0.07\n","Estimated Total Size (MB): 0.44\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":924},"id":"_vvnv5Bupr6G","executionInfo":{"status":"error","timestamp":1622988878632,"user_tz":-330,"elapsed":30801,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"86f68fdd-4eff-4798-c3b3-d9aa37668839"},"source":["from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from torch.optim.lr_scheduler import ExponentialLR\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9,)\n","\n","scheduler =ReduceLROnPlateau(optimizer=optimizer, patience=2, verbose=True)\n","\n","for epoch in range(1, 3):\n","    print(\"Epoch: \", epoch)\n","    train(model2, device, train_loader, optimizer, epoch)\n","    print(\"learning rate\", optimizer.param_groups[0]['lr'])\n","    # test(model2, device, test_loader)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch:  1\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["Training Average loss: 2.342123, Accuracy = (9.566667%)\n","learning rate 0.1\n","Epoch:  2\n"],"name":"stdout"},{"output_type":"stream","text":["Exception in thread Thread-78:\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.7/threading.py\", line 870, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/pin_memory.py\", line 25, in _pin_memory_loop\n","    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 113, in get\n","    return _ForkingPickler.loads(res)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\", line 282, in rebuild_storage_fd\n","    fd = df.detach()\n","  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 57, in detach\n","    with _resource_sharer.get_connection(self._id) as conn:\n","  File \"/usr/lib/python3.7/multiprocessing/resource_sharer.py\", line 87, in get_connection\n","    c = Client(address, authkey=process.current_process().authkey)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 492, in Client\n","    c = SocketClient(address)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 620, in SocketClient\n","    s.connect(address)\n","FileNotFoundError: [Errno 2] No such file or directory\n","\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-223-d51de57b4bea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"learning rate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# test(model2, device, test_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-194-bbca21246c22>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# for batch_idx, (data, target) in enumerate(pbar):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1138\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1139\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"RqOXbtubpr3G"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vpxlBBaRpr0G"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D7ysjleQprxn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9sx-inT0pruW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GGQESI69prrJ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OVgHwbWpoxoW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vDzji6rn9Rzc"},"source":["import torch.nn as nn\n","import torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"63uNbXkK9Vh4"},"source":["input = torch.randn(20, 5, 10, 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mx8SPgjo9a5e","executionInfo":{"elapsed":338,"status":"ok","timestamp":1622960098013,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"},"user_tz":-330},"outputId":"882d6ec6-068d-4309-e3c2-c8d88ef8bd67"},"source":["input.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([20, 5, 10, 10])"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kTQfo4Jd9beV","executionInfo":{"elapsed":368,"status":"ok","timestamp":1622961069867,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"},"user_tz":-330},"outputId":"5cf003c0-db76-4c5d-e533-90fe1a51cf0c"},"source":["input.size()[1:]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([5, 10, 10])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"eucYThqI9jvs"},"source":["m = nn.LayerNorm(input.size()[1:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3U3OvPyJQIf3","executionInfo":{"elapsed":347,"status":"ok","timestamp":1622964999154,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"},"user_tz":-330},"outputId":"52112501-3ed1-4341-f09f-77bf0a1219d8"},"source":["m"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LayerNorm((5, 10, 10), eps=1e-05, elementwise_affine=True)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"1xzUGT129rql"},"source":["output = m(input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i61jD4as9zal","executionInfo":{"elapsed":320,"status":"ok","timestamp":1622960229145,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"},"user_tz":-330},"outputId":"9807ec2c-3420-42cd-f763-b19db8db2825"},"source":["output.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([20, 5, 10, 10])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"vPtpE6bS98eL"},"source":[""],"execution_count":null,"outputs":[]}]}