{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Architectural_Basics.ipynb","provenance":[{"file_id":"1uJZvJdi5VprOQHROtJIHy0mnY2afjNlx","timestamp":1597458374158}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"0m2JWFliFfKT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597469198163,"user_tz":-330,"elapsed":1607,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}}},"source":["from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"DqTWLaM5GHgH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597469198164,"user_tz":-330,"elapsed":1016,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}}},"source":["\n","\n","torch.manual_seed(1)\n","batch_size = 128\n","use_cuda = torch.cuda.is_available()\n","\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ])),\n","    batch_size=batch_size, shuffle=True, **kwargs)\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"8fDefDhaFlwH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597469200030,"user_tz":-330,"elapsed":2143,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}}},"source":["from tqdm import tqdm\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    pbar = tqdm(train_loader)\n","    for batch_idx, (data, target) in enumerate(pbar):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n","\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EnsxYtr_-0x1","colab_type":"text"},"source":["## Summary of the trials\n","\n","Name: Net\n","\n","Description: Base architecture as provided by EVA, removed relu at conv7\n","\n","Parameters:  6.37 million\n","\n","number of Epochs - 2\n","\n","Accuracy - 98.7%\n","\n","------\n","\n","Name: Net2\n","\n","Description: Reduced the number of parameters by reducing channel size\n","\n","Parameters:  37k\n","\n","number of Epochs - 10\n","\n","Accuracy - 99%\n","\n","___\n","Name: Net 3\n","\n","Description : Add GAP to 5x5 \n","\n","parameters = 19.25K\n","\n","number of epochs -20\n","\n","accuracy - 98.98 % -  \n","\n","___\n","Add batch normalization \n","\n","Name: Net 4\n","\n","Description : GAP + Batch Normalization\n","\n","parameters = 19.45K\n","\n","number of epochs -20\n","\n","accuracy - 99.16 % - \n","\n","---\n","Go Deeper - Remove Padding\n","\n","Name: Net 5\n","\n","Description : Remove Padding. Go Deeper. \n","\n","parameters = 8.5K\n","\n","number of epochs -20\n","\n","accuracy - 99.32 % - \n","\n","---\n","Go Deeper - Remove Padding and increase parameters (channels)\n","\n","Name: Net 6\n","\n","Description : Remove Padding. Go Deeper. \n","\n","parameters = 19.3k\n","\n","number of epochs -20\n","\n","accuracy - 99.47 % - \n","\n"]},{"cell_type":"code","metadata":{"id":"h_Cx9q2QFgM7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597460463967,"user_tz":-330,"elapsed":3138,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}}},"source":["\n","class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)    #28x28x1 | 28x28x32 | 3\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)   #28x28x32| 28x28x64 | 5\n","        self.pool1 = nn.MaxPool2d(2, 2)                #28x28x64| 14x14x64 | 10\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)  #14x14x64| 14x14x128| 12\n","        self.conv4 = nn.Conv2d(128, 256, 3, padding=1) #14x14x128|14x14x256| 14\n","        self.pool2 = nn.MaxPool2d(2, 2)                #14x14x256|7x7x256  | 28\n","        self.conv5 = nn.Conv2d(256, 512, 3)            #7x7x256  |5x5x512  | 30\n","        self.conv6 = nn.Conv2d(512, 1024, 3)           #5x5x512  |3x3x1024 | 32\n","        self.conv7 = nn.Conv2d(1024, 10, 3)            #3x3x1024 |1x1x10   | 34\n","\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n","        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n","        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n","        x = self.conv7(x)\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xdydjYTZFyi3","colab":{"base_uri":"https://localhost:8080/","height":452},"executionInfo":{"status":"ok","timestamp":1597460473423,"user_tz":-330,"elapsed":12587,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"9fb0cb83-a275-44bb-859c-91bc58b7fe14"},"source":["!pip install torchsummary\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 32, 28, 28]             320\n","            Conv2d-2           [-1, 64, 28, 28]          18,496\n","         MaxPool2d-3           [-1, 64, 14, 14]               0\n","            Conv2d-4          [-1, 128, 14, 14]          73,856\n","            Conv2d-5          [-1, 256, 14, 14]         295,168\n","         MaxPool2d-6            [-1, 256, 7, 7]               0\n","            Conv2d-7            [-1, 512, 5, 5]       1,180,160\n","            Conv2d-8           [-1, 1024, 3, 3]       4,719,616\n","            Conv2d-9             [-1, 10, 1, 1]          92,170\n","================================================================\n","Total params: 6,379,786\n","Trainable params: 6,379,786\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 1.51\n","Params size (MB): 24.34\n","Estimated Total Size (MB): 25.85\n","----------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"MMWbLWO6FuHb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"status":"ok","timestamp":1597460515289,"user_tz":-330,"elapsed":54446,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"2efd3beb-2578-417c-a794-1a0681fe5422"},"source":["\n","model = Net().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 3):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","loss=0.037392038851976395 batch_id=468: 100%|██████████| 469/469 [00:18<00:00, 25.15it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0585, Accuracy: 9804/10000 (98.04%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0244371946901083 batch_id=468: 100%|██████████| 469/469 [00:18<00:00, 24.81it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0378, Accuracy: 9873/10000 (98.73%)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uQ8O97dgALL3","colab_type":"text"},"source":["2nd **Architecture**\n","\n","Reduce the number of parameters"]},{"cell_type":"code","metadata":{"id":"So5uk4EkHW6R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"status":"ok","timestamp":1597461057672,"user_tz":-330,"elapsed":7080,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"fb3c70e5-541d-4dec-d618-bed42cba05bc"},"source":["\n","class Net2(nn.Module):\n","    def __init__(self):\n","        super(Net2, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)    #28x28x1 | 28x28x32 | 3\n","        self.conv2 = nn.Conv2d(16, 16, 3, padding=1)   #28x28x32| 28x28x64 | 5\n","        self.pool1 = nn.MaxPool2d(2, 2)                #28x28x64| 14x14x64 | 10\n","        self.conv3 = nn.Conv2d(16,32 , 3, padding=1)  #14x14x64| 14x14x128| 12\n","        self.conv4 = nn.Conv2d(32, 32, 3, padding=1) #14x14x128|14x14x256| 14\n","        self.pool2 = nn.MaxPool2d(2, 2)                #14x14x256|7x7x256  | 28\n","        self.conv5 = nn.Conv2d(32, 32, 3)            #7x7x256  |5x5x512  | 30\n","        self.conv6 = nn.Conv2d(32, 32, 3)           #5x5x512  |3x3x1024 | 32\n","        self.conv7 = nn.Conv2d(32, 10, 3)            #3x3x1024 |1x1x10   | 34\n","\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n","        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n","        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n","        x = (self.conv7(x))\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x)\n","\n","\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net2().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 16, 28, 28]             160\n","            Conv2d-2           [-1, 16, 28, 28]           2,320\n","         MaxPool2d-3           [-1, 16, 14, 14]               0\n","            Conv2d-4           [-1, 32, 14, 14]           4,640\n","            Conv2d-5           [-1, 32, 14, 14]           9,248\n","         MaxPool2d-6             [-1, 32, 7, 7]               0\n","            Conv2d-7             [-1, 32, 5, 5]           9,248\n","            Conv2d-8             [-1, 32, 3, 3]           9,248\n","            Conv2d-9             [-1, 10, 1, 1]           2,890\n","================================================================\n","Total params: 37,754\n","Trainable params: 37,754\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.33\n","Params size (MB): 0.14\n","Estimated Total Size (MB): 0.48\n","----------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"kYG2BHiqCpuX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":676},"executionInfo":{"status":"ok","timestamp":1597461231894,"user_tz":-330,"elapsed":156112,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"cae28aa7-9f64-4bea-975b-73e1012ba661"},"source":["\n","model = Net2().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 10):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","loss=0.16880911588668823 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 31.00it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0969, Accuracy: 9713/10000 (97.13%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.055197637528181076 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 31.02it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0564, Accuracy: 9819/10000 (98.19%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.02744271606206894 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 31.08it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0501, Accuracy: 9835/10000 (98.35%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0967896357178688 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.90it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0351, Accuracy: 9882/10000 (98.82%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.02078404650092125 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.90it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0401, Accuracy: 9871/10000 (98.71%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.023922398686408997 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.78it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0368, Accuracy: 9883/10000 (98.83%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.026930727064609528 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 31.11it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0342, Accuracy: 9888/10000 (98.88%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.01513755414634943 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.97it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0330, Accuracy: 9891/10000 (98.91%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.005120225716382265 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 31.07it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0342, Accuracy: 9899/10000 (98.99%)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XOgi5xsJOn-T","colab_type":"text"},"source":["## GAP"]},{"cell_type":"code","metadata":{"id":"fR7HdQ4sDdIb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":417},"executionInfo":{"status":"ok","timestamp":1597463273877,"user_tz":-330,"elapsed":6486,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"34f455ba-45bb-4d85-ed6f-3d5ec02302e1"},"source":["# use GAP to reduce the kernals to less than 20K\n","class Net3(nn.Module):\n","    def __init__(self):\n","        super(Net3, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)    #28x28x1 | 28x28x32 | 3\n","        self.conv2 = nn.Conv2d(16, 16, 3, padding=1)   #28x28x32| 28x28x64 | 5\n","        self.pool1 = nn.MaxPool2d(2, 2)                #28x28x64| 14x14x64 | 10\n","        self.conv3 = nn.Conv2d(16,32 , 3, padding=1)  #14x14x64| 14x14x128| 12\n","        self.conv4 = nn.Conv2d(32, 32, 3, padding=1) #14x14x128|14x14x256| 14\n","        self.pool2 = nn.MaxPool2d(2, 2)                #14x14x256|7x7x256  | 28\n","        self.conv5 = nn.Conv2d(32, 10, 3)            #7x7x256  |5x5x512  | 30\n"," \n","        self.gap = nn.AvgPool2d(kernel_size=5)      #5x5x10 | 1x1x10\n","\n","\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n","        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))      \n","        x = (self.gap(self.conv5(x)))\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x)\n","\n","\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net3().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 16, 28, 28]             160\n","            Conv2d-2           [-1, 16, 28, 28]           2,320\n","         MaxPool2d-3           [-1, 16, 14, 14]               0\n","            Conv2d-4           [-1, 32, 14, 14]           4,640\n","            Conv2d-5           [-1, 32, 14, 14]           9,248\n","         MaxPool2d-6             [-1, 32, 7, 7]               0\n","            Conv2d-7             [-1, 10, 5, 5]           2,890\n","         AvgPool2d-8             [-1, 10, 1, 1]               0\n","================================================================\n","Total params: 19,258\n","Trainable params: 19,258\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.32\n","Params size (MB): 0.07\n","Estimated Total Size (MB): 0.40\n","----------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0V-GIbSlJHb8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597463595899,"user_tz":-330,"elapsed":317728,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"2b88b615-0e8f-46a4-d6a6-57f853655dae"},"source":["\n","model = Net3().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 20):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","loss=0.14937323331832886 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.04it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.1633, Accuracy: 9518/10000 (95.18%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.06795697659254074 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.00it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.1442, Accuracy: 9557/10000 (95.57%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0642104223370552 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.22it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0819, Accuracy: 9741/10000 (97.41%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.06015889719128609 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.07it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0864, Accuracy: 9729/10000 (97.29%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.017023932188749313 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.91it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0667, Accuracy: 9782/10000 (97.82%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.017976712435483932 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.94it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0617, Accuracy: 9793/10000 (97.93%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.08946848660707474 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.86it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0680, Accuracy: 9785/10000 (97.85%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.03215644508600235 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.97it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0522, Accuracy: 9832/10000 (98.32%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.005837814882397652 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.04it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0458, Accuracy: 9850/10000 (98.50%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.07883024960756302 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.11it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0411, Accuracy: 9869/10000 (98.69%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.018326736986637115 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.04it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0426, Accuracy: 9870/10000 (98.70%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.026254603639245033 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.06it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0380, Accuracy: 9879/10000 (98.79%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.002579539082944393 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.81it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0352, Accuracy: 9868/10000 (98.68%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.04157520830631256 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.91it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0423, Accuracy: 9854/10000 (98.54%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.009066746570169926 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.80it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0306, Accuracy: 9898/10000 (98.98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.04320579767227173 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.74it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0320, Accuracy: 9888/10000 (98.88%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.023991523310542107 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 31.95it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0304, Accuracy: 9898/10000 (98.98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.02462119795382023 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.15it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0387, Accuracy: 9869/10000 (98.69%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.05929945036768913 batch_id=468: 100%|██████████| 469/469 [00:14<00:00, 32.03it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0335, Accuracy: 9879/10000 (98.79%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-uDOPtgHKUSW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":486},"executionInfo":{"status":"ok","timestamp":1597463709151,"user_tz":-330,"elapsed":6077,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"2034c197-113c-449f-bc3f-451aaf8eddcc"},"source":["# Batch Normalization\n","class Net4(nn.Module):\n","    def __init__(self):\n","        super(Net4, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)    #28x28x1 | 28x28x32 | 3\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16, 16, 3, padding=1)   #28x28x32| 28x28x64 | 5\n","        self.bn2 = nn.BatchNorm2d(16)\n","        self.pool1 = nn.MaxPool2d(2, 2)                #28x28x64| 14x14x64 | 10\n","        self.conv3 = nn.Conv2d(16,32 , 3, padding=1)  #14x14x64| 14x14x128| 12\n","        self.bn3 = nn.BatchNorm2d(32)\n","        self.conv4 = nn.Conv2d(32, 32, 3, padding=1) #14x14x128|14x14x256| 14\n","        self.bn4 = nn.BatchNorm2d(32)\n","        self.pool2 = nn.MaxPool2d(2, 2)                #14x14x256|7x7x256  | 28\n","        self.conv5 = nn.Conv2d(32, 10, 3)            #7x7x256  |5x5x512  | 30\n"," \n","        self.gap = nn.AvgPool2d(kernel_size=5)      #5x5x10 | 1x1x10\n","\n","\n","    def forward(self, x):\n","        x = self.pool1(F.relu(self.bn2(self.conv2\n","                                       (F.relu(self.bn1(self.conv1(x)))))))\n","        x = self.pool2(F.relu(self.bn4(self.conv4\n","                              (F.relu(self.bn3(self.conv3(x)))))))      \n","        x = (self.gap(self.conv5(x)))\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x)\n","\n","\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net4().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 16, 28, 28]             160\n","       BatchNorm2d-2           [-1, 16, 28, 28]              32\n","            Conv2d-3           [-1, 16, 28, 28]           2,320\n","       BatchNorm2d-4           [-1, 16, 28, 28]              32\n","         MaxPool2d-5           [-1, 16, 14, 14]               0\n","            Conv2d-6           [-1, 32, 14, 14]           4,640\n","       BatchNorm2d-7           [-1, 32, 14, 14]              64\n","            Conv2d-8           [-1, 32, 14, 14]           9,248\n","       BatchNorm2d-9           [-1, 32, 14, 14]              64\n","        MaxPool2d-10             [-1, 32, 7, 7]               0\n","           Conv2d-11             [-1, 10, 5, 5]           2,890\n","        AvgPool2d-12             [-1, 10, 1, 1]               0\n","================================================================\n","Total params: 19,450\n","Trainable params: 19,450\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.61\n","Params size (MB): 0.07\n","Estimated Total Size (MB): 0.69\n","----------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"4WXfj4YtNI_e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597464048876,"user_tz":-330,"elapsed":330413,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"de031b22-0d6e-4aff-ce9a-d7773a8c0681"},"source":["\n","model = Net4().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 20):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["  0%|          | 0/469 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","loss=0.05175619199872017 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.87it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.1939, Accuracy: 9428/10000 (94.28%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.02295711822807789 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.93it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.1074, Accuracy: 9698/10000 (96.98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.07615318149328232 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.80it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0599, Accuracy: 9809/10000 (98.09%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.05141321197152138 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.84it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0569, Accuracy: 9818/10000 (98.18%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.010301430709660053 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.76it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0612, Accuracy: 9815/10000 (98.15%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.026148617267608643 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.71it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0464, Accuracy: 9850/10000 (98.50%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.02980346977710724 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.54it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0524, Accuracy: 9837/10000 (98.37%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.00871469546109438 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.89it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0377, Accuracy: 9873/10000 (98.73%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.024648500606417656 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.72it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0461, Accuracy: 9851/10000 (98.51%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.044675905257463455 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.81it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0796, Accuracy: 9740/10000 (97.40%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0028158987406641245 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 31.03it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0403, Accuracy: 9868/10000 (98.68%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0045344955287873745 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.72it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0358, Accuracy: 9883/10000 (98.83%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0010105102555826306 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.79it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0308, Accuracy: 9890/10000 (98.90%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.005598761141300201 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.76it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0283, Accuracy: 9906/10000 (99.06%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.008898325264453888 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.79it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0342, Accuracy: 9884/10000 (98.84%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.052991051226854324 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.61it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0372, Accuracy: 9873/10000 (98.73%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.009856713935732841 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.65it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0259, Accuracy: 9912/10000 (99.12%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.009974714368581772 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.91it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0346, Accuracy: 9885/10000 (98.85%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.015992887318134308 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 30.87it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0264, Accuracy: 9916/10000 (99.16%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WTfSFN1gNfm5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":743},"executionInfo":{"status":"ok","timestamp":1597469206806,"user_tz":-330,"elapsed":1736,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"a74274ac-bdda-4ae5-cb9e-7f8663329d63"},"source":["class Net5(nn.Module):\n","    def __init__(self):\n","        super(Net5, self).__init__()\n","        # Input Block\n","        self.convblock1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 26\n","\n","        # CONVOLUTION BLOCK 1\n","        self.convblock2 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 24\n","        self.convblock3 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU()\n","        ) # output_size = 22\n","        \n","\n","        # TRANSITION BLOCK 1\n","        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 11\n","        self.convblock4 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 11\n","\n","        # CONVOLUTION BLOCK 2\n","        self.convblock5 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 9\n","        self.convblock6 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 7\n","        self.convblock8 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3,3), padding=0, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU() \n","        ) # output_size = 5\n","\n","        self.convblock9 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3,3), padding=0, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU() \n","        ) # output_size = 3\n","\n","        # TRANSITION BLOCK 2\n","        #self.pool1 = nn.MaxPool2d(2, 2) # output_size = 11\n","        self.convblock10 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 5\n","\n","        # self.convblock11 = nn.Sequential(\n","        #     nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3,3), padding=0, bias=False),\n","        #     #nn.ReLU() \n","        # ) # output_size = 1\n","\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=3)\n","        )\n","    \n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.convblock2(x)\n","        x = self.convblock3(x)\n","        x = self.pool1(x)\n","        x = self.convblock4(x)\n","        x = self.convblock5(x)\n","        x = self.convblock6(x)\n","        #x = self.convblock7(x)\n","        x = self.convblock8(x)\n","        x = self.convblock9(x)\n","        x = self.convblock10(x)\n","        x = self.gap(x)\n","        #x = self.convblock11(x)\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x, dim=-1)\n","\n","\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net5().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 10, 26, 26]              90\n","       BatchNorm2d-2           [-1, 10, 26, 26]              20\n","              ReLU-3           [-1, 10, 26, 26]               0\n","            Conv2d-4           [-1, 10, 24, 24]             900\n","       BatchNorm2d-5           [-1, 10, 24, 24]              20\n","              ReLU-6           [-1, 10, 24, 24]               0\n","            Conv2d-7           [-1, 16, 22, 22]           1,440\n","       BatchNorm2d-8           [-1, 16, 22, 22]              32\n","              ReLU-9           [-1, 16, 22, 22]               0\n","        MaxPool2d-10           [-1, 16, 11, 11]               0\n","           Conv2d-11           [-1, 10, 11, 11]             160\n","      BatchNorm2d-12           [-1, 10, 11, 11]              20\n","             ReLU-13           [-1, 10, 11, 11]               0\n","           Conv2d-14             [-1, 10, 9, 9]             900\n","      BatchNorm2d-15             [-1, 10, 9, 9]              20\n","             ReLU-16             [-1, 10, 9, 9]               0\n","           Conv2d-17             [-1, 10, 7, 7]             900\n","      BatchNorm2d-18             [-1, 10, 7, 7]              20\n","             ReLU-19             [-1, 10, 7, 7]               0\n","           Conv2d-20             [-1, 16, 5, 5]           1,440\n","      BatchNorm2d-21             [-1, 16, 5, 5]              32\n","             ReLU-22             [-1, 16, 5, 5]               0\n","           Conv2d-23             [-1, 16, 3, 3]           2,304\n","      BatchNorm2d-24             [-1, 16, 3, 3]              32\n","             ReLU-25             [-1, 16, 3, 3]               0\n","           Conv2d-26             [-1, 10, 3, 3]             160\n","      BatchNorm2d-27             [-1, 10, 3, 3]              20\n","             ReLU-28             [-1, 10, 3, 3]               0\n","        AvgPool2d-29             [-1, 10, 1, 1]               0\n","================================================================\n","Total params: 8,510\n","Trainable params: 8,510\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.55\n","Params size (MB): 0.03\n","Estimated Total Size (MB): 0.59\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eqH6_0yFUbLN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597469554796,"user_tz":-330,"elapsed":346450,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"7b21e8db-c4ad-490b-8321-32d06938b7b9"},"source":["\n","model = Net5().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 20):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["loss=0.08935710042715073 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.16it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0894, Accuracy: 9826/10000 (98.26%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.13139687478542328 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.25it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0682, Accuracy: 9861/10000 (98.61%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.10327012091875076 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.21it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0668, Accuracy: 9859/10000 (98.59%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0678844004869461 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.25it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0400, Accuracy: 9903/10000 (99.03%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.09553942829370499 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 29.34it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0388, Accuracy: 9898/10000 (98.98%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.011925027705729008 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.01it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0340, Accuracy: 9909/10000 (99.09%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.030888719484210014 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.13it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0319, Accuracy: 9927/10000 (99.27%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.06579279899597168 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.15it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0320, Accuracy: 9912/10000 (99.12%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.01210123673081398 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.05it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0296, Accuracy: 9918/10000 (99.18%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.01691644825041294 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.12it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0268, Accuracy: 9924/10000 (99.24%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.02907833643257618 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.19it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0291, Accuracy: 9922/10000 (99.22%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.012047500349581242 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.98it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0297, Accuracy: 9919/10000 (99.19%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.015139497816562653 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.11it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0285, Accuracy: 9912/10000 (99.12%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.03840484097599983 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.27it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0306, Accuracy: 9907/10000 (99.07%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.01659456454217434 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.07it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0280, Accuracy: 9923/10000 (99.23%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.018076812848448753 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.01it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0256, Accuracy: 9926/10000 (99.26%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.03367912024259567 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.14it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0251, Accuracy: 9924/10000 (99.24%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.008389247581362724 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.27it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0234, Accuracy: 9936/10000 (99.36%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.013351759873330593 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.28it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0240, Accuracy: 9932/10000 (99.32%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4WGuNOJnUw_K","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":743},"executionInfo":{"status":"ok","timestamp":1597469900178,"user_tz":-330,"elapsed":2154,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"6dc6ac1a-620a-425f-ae85-8f7183f9adfe"},"source":["class Net6(nn.Module):\n","    def __init__(self):\n","        super(Net6, self).__init__()\n","        # Input Block\n","        self.convblock1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 26\n","\n","        # CONVOLUTION BLOCK 1\n","        self.convblock2 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 24\n","        self.convblock3 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU()\n","        ) # output_size = 22\n","        \n","\n","        # TRANSITION BLOCK 1\n","        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 11\n","        self.convblock4 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 11\n","\n","        # CONVOLUTION BLOCK 2\n","        self.convblock5 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 9\n","        self.convblock6 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=0, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU()\n","        ) # output_size = 7\n","        self.convblock8 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(3,3), padding=0, bias=False),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU() \n","        ) # output_size = 5\n","\n","        self.convblock9 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=(3,3), padding=0, bias=False),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU() \n","        ) # output_size = 3\n","\n","        # TRANSITION BLOCK 2\n","        #self.pool1 = nn.MaxPool2d(2, 2) # output_size = 11\n","        self.convblock10 = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 5\n","\n","\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=3)\n","        )\n","    \n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.convblock2(x)\n","        x = self.convblock3(x)\n","        x = self.pool1(x)\n","        x = self.convblock4(x)\n","        x = self.convblock5(x)\n","        x = self.convblock6(x)\n","        #x = self.convblock7(x)\n","        x = self.convblock8(x)\n","        x = self.convblock9(x)\n","        x = self.convblock10(x)\n","        x = self.gap(x)\n","        #x = self.convblock11(x)\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x, dim=-1)\n","\n","\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net6().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 10, 26, 26]              90\n","       BatchNorm2d-2           [-1, 10, 26, 26]              20\n","              ReLU-3           [-1, 10, 26, 26]               0\n","            Conv2d-4           [-1, 10, 24, 24]             900\n","       BatchNorm2d-5           [-1, 10, 24, 24]              20\n","              ReLU-6           [-1, 10, 24, 24]               0\n","            Conv2d-7           [-1, 16, 22, 22]           1,440\n","       BatchNorm2d-8           [-1, 16, 22, 22]              32\n","              ReLU-9           [-1, 16, 22, 22]               0\n","        MaxPool2d-10           [-1, 16, 11, 11]               0\n","           Conv2d-11           [-1, 10, 11, 11]             160\n","      BatchNorm2d-12           [-1, 10, 11, 11]              20\n","             ReLU-13           [-1, 10, 11, 11]               0\n","           Conv2d-14             [-1, 10, 9, 9]             900\n","      BatchNorm2d-15             [-1, 10, 9, 9]              20\n","             ReLU-16             [-1, 10, 9, 9]               0\n","           Conv2d-17             [-1, 16, 7, 7]           1,440\n","      BatchNorm2d-18             [-1, 16, 7, 7]              32\n","             ReLU-19             [-1, 16, 7, 7]               0\n","           Conv2d-20             [-1, 32, 5, 5]           4,608\n","      BatchNorm2d-21             [-1, 32, 5, 5]              64\n","             ReLU-22             [-1, 32, 5, 5]               0\n","           Conv2d-23             [-1, 32, 3, 3]           9,216\n","      BatchNorm2d-24             [-1, 32, 3, 3]              64\n","             ReLU-25             [-1, 32, 3, 3]               0\n","           Conv2d-26             [-1, 10, 3, 3]             320\n","      BatchNorm2d-27             [-1, 10, 3, 3]              20\n","             ReLU-28             [-1, 10, 3, 3]               0\n","        AvgPool2d-29             [-1, 10, 1, 1]               0\n","================================================================\n","Total params: 19,366\n","Trainable params: 19,366\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.57\n","Params size (MB): 0.07\n","Estimated Total Size (MB): 0.65\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NyhUrhTGm8B_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597470265084,"user_tz":-330,"elapsed":348402,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"bbadd24d-5d2e-49dd-e7b5-1e9515ec722d"},"source":["\n","model = Net6().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 20):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["loss=0.057814646512269974 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.85it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0848, Accuracy: 9858/10000 (98.58%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.13606026768684387 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.19it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0560, Accuracy: 9885/10000 (98.85%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.1074705645442009 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.11it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0467, Accuracy: 9906/10000 (99.06%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.022599957883358 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.03it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0313, Accuracy: 9920/10000 (99.20%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.03470364212989807 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.10it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0293, Accuracy: 9928/10000 (99.28%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.04289378598332405 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.10it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0247, Accuracy: 9940/10000 (99.40%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.018098624423146248 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.05it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0267, Accuracy: 9930/10000 (99.30%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0083705959841609 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.91it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0261, Accuracy: 9933/10000 (99.33%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.05981002375483513 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.96it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0248, Accuracy: 9924/10000 (99.24%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.011799114756286144 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.06it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0262, Accuracy: 9926/10000 (99.26%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0167903583496809 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.96it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0228, Accuracy: 9934/10000 (99.34%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.017734402790665627 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.24it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0223, Accuracy: 9935/10000 (99.35%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.01602179929614067 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.17it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0210, Accuracy: 9938/10000 (99.38%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.008758480660617352 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.96it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0230, Accuracy: 9939/10000 (99.39%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.006571419537067413 batch_id=468: 100%|██████████| 469/469 [00:15<00:00, 29.32it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0227, Accuracy: 9933/10000 (99.33%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.006395924370735884 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.12it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0224, Accuracy: 9937/10000 (99.37%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.011473494581878185 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 29.16it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0228, Accuracy: 9940/10000 (99.40%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.027770625427365303 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.90it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0209, Accuracy: 9937/10000 (99.37%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.007121365983039141 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.93it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0200, Accuracy: 9947/10000 (99.47%)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FV8YTf2yuujC","colab_type":"text"},"source":["# Experimetal - GO DEEPER"]},{"cell_type":"code","metadata":{"id":"Z5C7847_oH2Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":812},"executionInfo":{"status":"ok","timestamp":1597472666625,"user_tz":-330,"elapsed":1397,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"c2eb9d86-f633-4411-f6b0-b2a1c8d32030"},"source":["class Net7(nn.Module):\n","    def __init__(self):\n","        super(Net7, self).__init__()\n","        # Input Block\n","        self.convblock1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 28\n","\n","        # CONVOLUTION BLOCK 1\n","        self.convblock2 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 28\n","        self.convblock3 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU()\n","        ) # output_size = 28\n","        \n","#------------------\n","\n","        # TRANSITION BLOCK 1\n","        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 11\n","        self.convblock4 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 14\n","\n","#-------------\n","        # CONVOLUTION BLOCK 2\n","        self.convblock5 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 14\n","        self.convblock6 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU()\n","        ) # output_size = 14\n","\n","#---------------------\n","\n","        # TRANSITION BLOCK 2\n","        self.pool2 = nn.MaxPool2d(2, 2) # output_size = 11\n","        self.convblock7 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 7\n","\n","#-----------------------\n","\n","        self.convblock8 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3,3), padding=1, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU() \n","        ) # output_size = 7\n","\n","        self.convblock9 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3,3), padding=0, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU()) #5  \n","\n","#-------------------------------\n","        # 1x1 reduction block\n","        self.red_block = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 5\n","\n","#----------------------------------------\n","\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=5)\n","        )\n","    \n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.convblock2(x)\n","        x = self.convblock3(x)\n","        x = self.pool1(x)\n","        x = self.convblock4(x)\n","        x = self.convblock5(x)\n","        x = self.convblock6(x)\n","        x = self.pool2(x)\n","        x = self.convblock7(x)\n","        x = self.convblock8(x)\n","        x = self.convblock9(x)\n","        x = self.red_block(x)\n","        x = self.gap(x)\n","        #x = self.convblock11(x)\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x, dim=-1)\n","\n","\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net7().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 10, 28, 28]              90\n","       BatchNorm2d-2           [-1, 10, 28, 28]              20\n","              ReLU-3           [-1, 10, 28, 28]               0\n","            Conv2d-4           [-1, 10, 28, 28]             900\n","       BatchNorm2d-5           [-1, 10, 28, 28]              20\n","              ReLU-6           [-1, 10, 28, 28]               0\n","            Conv2d-7           [-1, 16, 28, 28]           1,440\n","       BatchNorm2d-8           [-1, 16, 28, 28]              32\n","              ReLU-9           [-1, 16, 28, 28]               0\n","        MaxPool2d-10           [-1, 16, 14, 14]               0\n","           Conv2d-11           [-1, 10, 14, 14]             160\n","      BatchNorm2d-12           [-1, 10, 14, 14]              20\n","             ReLU-13           [-1, 10, 14, 14]               0\n","           Conv2d-14           [-1, 10, 14, 14]             900\n","      BatchNorm2d-15           [-1, 10, 14, 14]              20\n","             ReLU-16           [-1, 10, 14, 14]               0\n","           Conv2d-17           [-1, 16, 14, 14]           1,440\n","      BatchNorm2d-18           [-1, 16, 14, 14]              32\n","             ReLU-19           [-1, 16, 14, 14]               0\n","        MaxPool2d-20             [-1, 16, 7, 7]               0\n","           Conv2d-21             [-1, 10, 7, 7]             160\n","      BatchNorm2d-22             [-1, 10, 7, 7]              20\n","             ReLU-23             [-1, 10, 7, 7]               0\n","           Conv2d-24             [-1, 16, 7, 7]           1,440\n","      BatchNorm2d-25             [-1, 16, 7, 7]              32\n","             ReLU-26             [-1, 16, 7, 7]               0\n","           Conv2d-27             [-1, 16, 5, 5]           2,304\n","      BatchNorm2d-28             [-1, 16, 5, 5]              32\n","             ReLU-29             [-1, 16, 5, 5]               0\n","           Conv2d-30             [-1, 10, 5, 5]             160\n","      BatchNorm2d-31             [-1, 10, 5, 5]              20\n","             ReLU-32             [-1, 10, 5, 5]               0\n","        AvgPool2d-33             [-1, 10, 1, 1]               0\n","================================================================\n","Total params: 9,242\n","Trainable params: 9,242\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.88\n","Params size (MB): 0.04\n","Estimated Total Size (MB): 0.92\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dWtRk269vQkT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597473033750,"user_tz":-330,"elapsed":350511,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"9c992f90-c5e3-46f4-c387-c035dbcffc06"},"source":["\n","model = Net7().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 20):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["loss=0.15551435947418213 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.64it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.1246, Accuracy: 9747/10000 (97.47%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.096739262342453 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.58it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.1651, Accuracy: 9582/10000 (95.82%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.08655428886413574 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.82it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0688, Accuracy: 9842/10000 (98.42%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.07699770480394363 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.66it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0523, Accuracy: 9880/10000 (98.80%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.04377904534339905 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.56it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0447, Accuracy: 9891/10000 (98.91%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.02040863409638405 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.81it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0506, Accuracy: 9873/10000 (98.73%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.019033528864383698 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.78it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0716, Accuracy: 9790/10000 (97.90%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.018931889906525612 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.83it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0350, Accuracy: 9916/10000 (99.16%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.02678045444190502 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.60it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0402, Accuracy: 9900/10000 (99.00%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.06099111959338188 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.92it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0633, Accuracy: 9822/10000 (98.22%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.05714426562190056 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.68it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0326, Accuracy: 9916/10000 (99.16%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.02107551507651806 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.67it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0399, Accuracy: 9890/10000 (98.90%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.0170516949146986 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.83it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0320, Accuracy: 9915/10000 (99.15%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.007126814220100641 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.83it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0382, Accuracy: 9890/10000 (98.90%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.05262577161192894 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.79it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0462, Accuracy: 9872/10000 (98.72%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.007466560695320368 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.88it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0477, Accuracy: 9861/10000 (98.61%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.006343365181237459 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.60it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0325, Accuracy: 9913/10000 (99.13%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.018262365832924843 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.79it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0283, Accuracy: 9919/10000 (99.19%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.029751315712928772 batch_id=468: 100%|██████████| 469/469 [00:16<00:00, 28.87it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0257, Accuracy: 9928/10000 (99.28%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CQn9y4vYyrSY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":968},"executionInfo":{"status":"ok","timestamp":1597473219441,"user_tz":-330,"elapsed":2231,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"c30b468b-85b8-4511-991f-323537b3afb4"},"source":["class Net8(nn.Module):\n","    def __init__(self):\n","        super(Net8, self).__init__()\n","        # Input Block\n","        self.convblock1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 28\n","\n","        # CONVOLUTION BLOCK 1\n","        self.convblock2 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 28\n","        self.convblock3 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU()\n","        ) # output_size = 28\n","\n","        self.convblock3a = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU()\n","        ) # output_size = 28\n","        \n","#------------------\n","\n","        # TRANSITION BLOCK 1\n","        self.pool1 = nn.MaxPool2d(2, 2) # output_size = 11\n","        self.convblock4 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 14\n","\n","#-------------\n","        # CONVOLUTION BLOCK 2\n","        self.convblock5 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 14\n","        self.convblock6 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU()\n","        ) # output_size = 14\n","\n","        self.convblock6a = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3, 3), padding=1, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU()\n","        ) # output_size = 14\n","\n","#---------------------\n","\n","        # TRANSITION BLOCK 2\n","        self.pool2 = nn.MaxPool2d(2, 2) # output_size = 11\n","        self.convblock7 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 7\n","\n","#-----------------------\n","\n","        self.convblock8 = nn.Sequential(\n","            nn.Conv2d(in_channels=10, out_channels=16, kernel_size=(3,3), padding=1, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU() \n","        ) # output_size = 7\n","\n","        self.convblock9 = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3,3), padding=1, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU()) #5  \n","\n","        self.convblock9a = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=(3,3), padding=0, bias=False),\n","            nn.BatchNorm2d(16),\n","            nn.ReLU()) #5 \n","\n","#-------------------------------\n","        # 1x1 reduction block\n","        self.red_block = nn.Sequential(\n","            nn.Conv2d(in_channels=16, out_channels=10, kernel_size=(1, 1), padding=0, bias=False),\n","            nn.BatchNorm2d(10),\n","            nn.ReLU()\n","        ) # output_size = 5\n","\n","#----------------------------------------\n","\n","        self.gap = nn.Sequential(\n","            nn.AvgPool2d(kernel_size=5)\n","        )\n","    \n","\n","    def forward(self, x):\n","        x = self.convblock1(x)\n","        x = self.convblock2(x)\n","        x = self.convblock3(x)\n","        x = self.convblock3a(x)\n","        x = self.pool1(x)\n","        x = self.convblock4(x)\n","        x = self.convblock5(x)\n","        x = self.convblock6(x)\n","        x = self.convblock6a(x)\n","        x = self.pool2(x)\n","        x = self.convblock7(x)\n","        x = self.convblock8(x)\n","        x = self.convblock9(x)\n","        x = self.convblock9a(x)\n","        x = self.red_block(x)\n","        x = self.gap(x)\n","        #x = self.convblock11(x)\n","        x = x.view(-1, 10)\n","        return F.log_softmax(x, dim=-1)\n","\n","\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","model = Net8().to(device)\n","summary(model, input_size=(1, 28, 28))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 10, 28, 28]              90\n","       BatchNorm2d-2           [-1, 10, 28, 28]              20\n","              ReLU-3           [-1, 10, 28, 28]               0\n","            Conv2d-4           [-1, 10, 28, 28]             900\n","       BatchNorm2d-5           [-1, 10, 28, 28]              20\n","              ReLU-6           [-1, 10, 28, 28]               0\n","            Conv2d-7           [-1, 16, 28, 28]           1,440\n","       BatchNorm2d-8           [-1, 16, 28, 28]              32\n","              ReLU-9           [-1, 16, 28, 28]               0\n","           Conv2d-10           [-1, 16, 28, 28]           2,304\n","      BatchNorm2d-11           [-1, 16, 28, 28]              32\n","             ReLU-12           [-1, 16, 28, 28]               0\n","        MaxPool2d-13           [-1, 16, 14, 14]               0\n","           Conv2d-14           [-1, 10, 14, 14]             160\n","      BatchNorm2d-15           [-1, 10, 14, 14]              20\n","             ReLU-16           [-1, 10, 14, 14]               0\n","           Conv2d-17           [-1, 10, 14, 14]             900\n","      BatchNorm2d-18           [-1, 10, 14, 14]              20\n","             ReLU-19           [-1, 10, 14, 14]               0\n","           Conv2d-20           [-1, 16, 14, 14]           1,440\n","      BatchNorm2d-21           [-1, 16, 14, 14]              32\n","             ReLU-22           [-1, 16, 14, 14]               0\n","           Conv2d-23           [-1, 16, 14, 14]           2,304\n","      BatchNorm2d-24           [-1, 16, 14, 14]              32\n","             ReLU-25           [-1, 16, 14, 14]               0\n","        MaxPool2d-26             [-1, 16, 7, 7]               0\n","           Conv2d-27             [-1, 10, 7, 7]             160\n","      BatchNorm2d-28             [-1, 10, 7, 7]              20\n","             ReLU-29             [-1, 10, 7, 7]               0\n","           Conv2d-30             [-1, 16, 7, 7]           1,440\n","      BatchNorm2d-31             [-1, 16, 7, 7]              32\n","             ReLU-32             [-1, 16, 7, 7]               0\n","           Conv2d-33             [-1, 16, 7, 7]           2,304\n","      BatchNorm2d-34             [-1, 16, 7, 7]              32\n","             ReLU-35             [-1, 16, 7, 7]               0\n","           Conv2d-36             [-1, 16, 5, 5]           2,304\n","      BatchNorm2d-37             [-1, 16, 5, 5]              32\n","             ReLU-38             [-1, 16, 5, 5]               0\n","           Conv2d-39             [-1, 10, 5, 5]             160\n","      BatchNorm2d-40             [-1, 10, 5, 5]              20\n","             ReLU-41             [-1, 10, 5, 5]               0\n","        AvgPool2d-42             [-1, 10, 1, 1]               0\n","================================================================\n","Total params: 16,250\n","Trainable params: 16,250\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 1.26\n","Params size (MB): 0.06\n","Estimated Total Size (MB): 1.32\n","----------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Epd3hcjs0ls1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597473637882,"user_tz":-330,"elapsed":369578,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"319e5c7c-3e42-407b-c161-00a38b32754b"},"source":["\n","model = Net8().to(device)\n","optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","\n","for epoch in range(1, 20):\n","    train(model, device, train_loader, optimizer, epoch)\n","    test(model, device, test_loader)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["loss=0.16752409934997559 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.05it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.1427, Accuracy: 9671/10000 (96.71%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.056088078767061234 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.13it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0677, Accuracy: 9834/10000 (98.34%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.13279898464679718 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.16it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0637, Accuracy: 9841/10000 (98.41%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.07441216707229614 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.11it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0502, Accuracy: 9884/10000 (98.84%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.013030261732637882 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.17it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0438, Accuracy: 9881/10000 (98.81%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.08251157402992249 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.09it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0415, Accuracy: 9882/10000 (98.82%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.05942970886826515 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.18it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0467, Accuracy: 9878/10000 (98.78%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.029033279046416283 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.10it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0285, Accuracy: 9923/10000 (99.23%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.011834035627543926 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.12it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0384, Accuracy: 9884/10000 (98.84%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.07045648992061615 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.11it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0360, Accuracy: 9904/10000 (99.04%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.03315376117825508 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.04it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0270, Accuracy: 9924/10000 (99.24%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.04435138404369354 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.18it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0223, Accuracy: 9932/10000 (99.32%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.011159274727106094 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.15it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0323, Accuracy: 9910/10000 (99.10%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.01094808429479599 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.17it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0213, Accuracy: 9937/10000 (99.37%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.004245539661496878 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.07it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0250, Accuracy: 9928/10000 (99.28%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.014226299710571766 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.15it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0235, Accuracy: 9934/10000 (99.34%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.007844758220016956 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.02it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0217, Accuracy: 9939/10000 (99.39%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.02504863403737545 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.22it/s]\n","  0%|          | 0/469 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0341, Accuracy: 9902/10000 (99.02%)\n","\n"],"name":"stdout"},{"output_type":"stream","text":["loss=0.04582930728793144 batch_id=468: 100%|██████████| 469/469 [00:17<00:00, 27.18it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["\n","Test set: Average loss: 0.0234, Accuracy: 9932/10000 (99.32%)\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1ii9CvLO26n0","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}