{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"YOLO-HAT and Mask-v2.ipynb","provenance":[{"file_id":"1o71UI_z29I3JpIVNuJf-t2xjWtCdWUv_","timestamp":1603627127383},{"file_id":"1Ict6Sw7VEOFuAlhesnY48FjMiigajxeG","timestamp":1603423738528}],"collapsed_sections":[],"mount_file_id":"1Ofuse8gJHtSDRryBLjZYsacA-vMHm9MK","authorship_tag":"ABX9TyPf1lGyA1rfuVlH48atjhX/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"cXzTFe5lfwzh","executionInfo":{"status":"ok","timestamp":1603629684642,"user_tz":-330,"elapsed":24125,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"01b7b099-4f00-44a5-d59e-70eca532c567","colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# load Google Driver\n","from google.colab import drive\n","import sys, os\n","drive.mount('/content/drive')\n","\n","my_path = '/content/drive/My Drive/Computer Vision/Extensive VisionAI (EVA5)/13_yolo_v2'\n","sys.path.append(my_path)\n","os.listdir(my_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['YoloV3', 'YOLO-Walle.ipynb', 'backup', 'YOLO-HAT and Mask.ipynb']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"GjSwqgOhoE6L","executionInfo":{"status":"ok","timestamp":1603629684643,"user_tz":-330,"elapsed":22167,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"3d232c03-c91b-4392-ab47-a3c6b9086d80","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["cd 'drive/My Drive/Computer Vision/Extensive VisionAI (EVA5)/13_yolo_v2/YoloV3'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Computer Vision/Extensive VisionAI (EVA5)/13_yolo_v2/YoloV3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M-VbtuMfxokg"},"source":["# !git clone https://github.com/theschoolofai/YoloV3.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_kGs2-3mxxCS","executionInfo":{"status":"ok","timestamp":1603629686063,"user_tz":-330,"elapsed":4866,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"839dde38-3346-4f9d-e336-058afdd557fd","colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":[" annotation_tool   results.json      train_out\n"," cfg\t\t   results.png\t    'train_out (1) - images'\n"," data\t\t   results.txt\t     train.py\n"," detect.py\t   runs\t\t    'ubdivisions=1'\n"," models.py\t   test_batch0.png   utils\n"," __pycache__\t   test.py\t     vim.exe.stackdump\n"," README.md\t   ting\t\t     weights\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qTzki6PgyCJC","executionInfo":{"status":"ok","timestamp":1603629688765,"user_tz":-330,"elapsed":5590,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"d9f7175f-8d5c-4072-8c4d-216a06aaa3a6","colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["import time\n","import glob\n","import torch\n","import os\n","\n","from IPython.display import Image, clear_output \n","print('PyTorch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PyTorch 1.6.0+cu101 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15079MB, multi_processor_count=40)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4heRMJ_8ijUH"},"source":["# !python train.py --data data/YoloV3_Dataset/train.data --batch 16 --cache --cfg cfg/yolov3-hat.cfg --epochs 100"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YTQnQ7U1C05e","outputId":"24ada802-0a6d-4209-ac82-725c22968a6c","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python train.py --data data/YoloV3_Dataset/train.data --batch 16 --cache --cfg cfg/yolov3-hat.cfg --epochs 200 --weights='weights/last.pt'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=16, bucket='', cache_images=True, cfg='cfg/yolov3-hat.cfg', data='data/YoloV3_Dataset/train.data', device='', epochs=200, evolve=False, img_size=[512], multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/last.pt')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla T4', total_memory=15079MB)\n","\n","2020-10-25 13:16:49.044799: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","Model Summary: 225 layers, 6.25895e+07 parameters, 6.25895e+07 gradients\n","Caching labels (3032 found, 129 missing, 38 empty, 0 duplicate, for 3199 images): 100% 3199/3199 [00:02<00:00, 1132.30it/s]\n","Caching images (1.8GB): 100% 3199/3199 [00:26<00:00, 122.41it/s]\n","Caching labels (296 found, 14 missing, 7 empty, 0 duplicate, for 317 images): 100% 317/317 [00:00<00:00, 1169.34it/s]\n","Caching images (0.1GB): 100% 317/317 [00:03<00:00, 91.93it/s]\n","Image sizes 512 - 512 train, 512 test\n","Using 2 dataloader workers\n","Starting training for 200 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","    34/199     11.8G      1.84       0.9     0.122      2.86        76       512: 100% 200/200 [05:31<00:00,  1.66s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1:   0% 0/20 [00:00<?, ?it/s]/content/drive/My Drive/Computer Vision/Extensive VisionAI (EVA5)/13_yolo_v2/YoloV3/utils/utils.py:531: UserWarning: This overload of nonzero is deprecated:\n","\tnonzero()\n","Consider using one of the following signatures instead:\n","\tnonzero(*, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)\n","  i, j = (x[:, 5:] > conf_thres).nonzero().t()\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:11<00:00,  1.80it/s]\n","                 all       317  1.53e+03     0.557     0.668     0.552     0.607\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/torch/cuda/memory.py:346: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n","  FutureWarning)\n","    35/199     11.8G      1.81     0.863     0.104      2.77        95       512: 100% 200/200 [05:35<00:00,  1.68s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:08<00:00,  2.23it/s]\n","                 all       317  1.53e+03     0.566     0.642     0.534     0.601\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    36/199     11.8G       1.8      0.84    0.0981      2.74       134       512: 100% 200/200 [05:35<00:00,  1.68s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:08<00:00,  2.23it/s]\n","                 all       317  1.53e+03     0.584     0.666     0.545     0.621\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    37/199     11.8G       1.9      1.06     0.192      3.15       134       512: 100% 200/200 [05:35<00:00,  1.68s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:09<00:00,  2.20it/s]\n","                 all       317  1.53e+03     0.546     0.666     0.546     0.599\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    38/199     11.8G      1.89      1.04       0.2      3.14       110       512: 100% 200/200 [05:35<00:00,  1.68s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:09<00:00,  2.19it/s]\n","                 all       317  1.53e+03      0.52     0.673     0.536     0.584\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    39/199     11.8G      1.87      1.04     0.197      3.11       140       512: 100% 200/200 [05:34<00:00,  1.67s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:08<00:00,  2.23it/s]\n","                 all       317  1.53e+03      0.57     0.651      0.55     0.607\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    40/199     11.8G      1.86         1     0.186      3.05        88       512: 100% 200/200 [05:35<00:00,  1.68s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:09<00:00,  2.19it/s]\n","                 all       317  1.53e+03     0.542     0.678      0.55     0.601\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    41/199     11.8G      1.85     0.989     0.171      3.01       119       512: 100% 200/200 [05:35<00:00,  1.68s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:09<00:00,  2.21it/s]\n","                 all       317  1.53e+03     0.557     0.632     0.532     0.592\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    42/199     11.8G      1.86      1.01     0.158      3.03       104       512: 100% 200/200 [05:35<00:00,  1.68s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:08<00:00,  2.24it/s]\n","                 all       317  1.53e+03     0.536     0.663     0.546     0.592\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    43/199     11.8G       1.8     0.991     0.142      2.93       110       512: 100% 200/200 [05:35<00:00,  1.68s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:09<00:00,  2.20it/s]\n","                 all       317  1.53e+03     0.566     0.654     0.542     0.606\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    44/199     11.8G      1.81     0.981     0.158      2.95        87       512: 100% 200/200 [05:35<00:00,  1.68s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:08<00:00,  2.23it/s]\n","                 all       317  1.53e+03     0.551     0.642      0.53     0.593\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    45/199     11.8G      1.81     0.961      0.15      2.92       128       512: 100% 200/200 [05:35<00:00,  1.68s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:08<00:00,  2.23it/s]\n","                 all       317  1.53e+03     0.532      0.65     0.518     0.585\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    46/199     11.8G      1.78     0.989     0.155      2.92        97       512: 100% 200/200 [05:35<00:00,  1.68s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:08<00:00,  2.25it/s]\n","                 all       317  1.53e+03     0.567     0.643     0.538     0.602\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    47/199     11.8G      1.75      0.96     0.145      2.86        79       512: 100% 200/200 [05:35<00:00,  1.68s/it]\n","               Class    Images   Targets         P         R   mAP@0.5        F1: 100% 20/20 [00:08<00:00,  2.23it/s]\n","                 all       317  1.53e+03     0.576     0.654     0.536     0.611\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","    48/199     11.8G      1.75      0.92     0.132       2.8        91       512:  18% 35/200 [00:59<04:35,  1.67s/it]"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-4Cf5zHaZv7R","executionInfo":{"status":"ok","timestamp":1603624938536,"user_tz":-330,"elapsed":1287040,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"f1c40388-447f-46b9-ed80-16c0fb3ced76","colab":{"base_uri":"https://localhost:8080/","height":672}},"source":["!python train.py --data data/YoloV3_Dataset/train.data --batch 16 --cache --cfg cfg/yolov3-hat.cfg --epochs 200 --weights='weights/last.pt'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(accumulate=4, adam=False, batch_size=16, bucket='', cache_images=True, cfg='cfg/yolov3-hat.cfg', data='data/YoloV3_Dataset/train.data', device='', epochs=200, evolve=False, img_size=[512], multi_scale=False, name='', nosave=False, notest=False, rect=False, resume=False, single_cls=False, weights='weights/best.pt')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla P4', total_memory=7611MB)\n","\n","2020-10-25 11:00:53.636584: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n","Run 'tensorboard --logdir=runs' to view tensorboard at http://localhost:6006/\n","Model Summary: 225 layers, 6.25895e+07 parameters, 6.25895e+07 gradients\n","Caching labels (3032 found, 129 missing, 38 empty, 0 duplicate, for 3199 images): 100% 3199/3199 [09:04<00:00,  5.88it/s]\n","Caching images (1.8GB): 100% 3199/3199 [10:05<00:00,  5.28it/s]\n","Caching labels (296 found, 14 missing, 7 empty, 0 duplicate, for 317 images): 100% 317/317 [00:55<00:00,  5.73it/s]\n","Caching images (0.1GB): 100% 317/317 [01:01<00:00,  5.12it/s]\n","Image sizes 512 - 512 train, 512 test\n","Using 2 dataloader workers\n","Starting training for 200 epochs...\n","\n","     Epoch   gpu_mem      GIoU       obj       cls     total   targets  img_size\n","  0% 0/200 [00:00<?, ?it/s]Traceback (most recent call last):\n","  File \"train.py\", line 430, in <module>\n","    train()  # train normally\n","  File \"train.py\", line 263, in train\n","    pred = model(imgs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/content/drive/My Drive/Computer Vision/Extensive VisionAI (EVA5)/13_yolo_v2/YoloV3/models.py\", line 235, in forward\n","    return self.forward_once(x)\n","  File \"/content/drive/My Drive/Computer Vision/Extensive VisionAI (EVA5)/13_yolo_v2/YoloV3/models.py\", line 289, in forward_once\n","    x = module(x)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\", line 117, in forward\n","    input = module(input)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 722, in _call_impl\n","    result = self.forward(*input, **kwargs)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 419, in forward\n","    return self._conv_forward(input, self.weight)\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 416, in _conv_forward\n","    self.padding, self.dilation, self.groups)\n","RuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 7.43 GiB total capacity; 6.72 GiB already allocated; 6.94 MiB free; 6.74 GiB reserved in total by PyTorch)\n","  0% 0/200 [00:01<?, ?it/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nlLIYRKX5bgo","executionInfo":{"status":"ok","timestamp":1603620666011,"user_tz":-330,"elapsed":9943,"user":{"displayName":"Vidhya Shankar V","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgibVFpmsqOpOYqW5r1kRBYXglwZsL14PgzsJPT=s64","userId":"06672572748869395626"}},"outputId":"8f28742b-c8a0-4d75-b845-1864be5fede7","colab":{"base_uri":"https://localhost:8080/","height":338}},"source":["!python detect.py --conf-thres 0.3 --output train_out --source 'data/vid-samples1'# --weights='weights/last.pt'"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(agnostic_nms=False, augment=False, cfg='cfg/yolov3-hat.cfg', classes=None, conf_thres=0.3, device='', fourcc='mp4v', half=False, img_size=512, iou_thres=0.6, names='data/YoloV3_Dataset/classes.txt', output='train_out', save_txt=False, source='data/vid-samples1', view_img=False, weights='weights/yolov3-spp-ultralytics.pt')\n","Using CUDA device0 _CudaDeviceProperties(name='Tesla T4', total_memory=15079MB)\n","\n","Model Summary: 225 layers, 6.25895e+07 parameters, 6.25895e+07 gradients\n","Traceback (most recent call last):\n","  File \"detect.py\", line 186, in <module>\n","    detect()\n","  File \"detect.py\", line 26, in detect\n","    model.load_state_dict(torch.load(weights, map_location=device)['model'])\n","  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 1045, in load_state_dict\n","    self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n","RuntimeError: Error(s) in loading state_dict for Darknet:\n","\tsize mismatch for module_list.88.Conv2d.weight: copying a param with shape torch.Size([255, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([27, 1024, 1, 1]).\n","\tsize mismatch for module_list.88.Conv2d.bias: copying a param with shape torch.Size([255]) from checkpoint, the shape in current model is torch.Size([27]).\n","\tsize mismatch for module_list.100.Conv2d.weight: copying a param with shape torch.Size([255, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([27, 512, 1, 1]).\n","\tsize mismatch for module_list.100.Conv2d.bias: copying a param with shape torch.Size([255]) from checkpoint, the shape in current model is torch.Size([27]).\n","\tsize mismatch for module_list.112.Conv2d.weight: copying a param with shape torch.Size([255, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([27, 256, 1, 1]).\n","\tsize mismatch for module_list.112.Conv2d.bias: copying a param with shape torch.Size([255]) from checkpoint, the shape in current model is torch.Size([27]).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6RUf-zkLL51Z"},"source":[""],"execution_count":null,"outputs":[]}]}